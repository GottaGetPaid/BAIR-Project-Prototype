<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
    <style>
        .mic-btn-large {
            position: relative;
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: linear-gradient(135deg, #60a5fa 0%, #3b82f6 100%);
            border: none;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(59, 130, 246, 0.4);
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        /* Dark mode styling */
        @media (prefers-color-scheme: dark) {
            .mic-btn-large {
                background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
                box-shadow: 0 4px 15px rgba(59, 130, 246, 0.5);
            }
        }
        
        .mic-btn-large:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(59, 130, 246, 0.6);
        }
        
        .mic-btn-large:active {
            transform: scale(0.95);
        }
        
        .mic-btn-large.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }
        
        .voice-level-indicator {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 60%;
            height: 60%;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.4);
            opacity: 0;
            transition: transform 0.03s ease-out, opacity 0.3s ease;
            transform: translate(-50%, -50%) scale(0.3);
            transform-origin: center;
        }
        
        .mic-btn-large.recording .voice-level-indicator {
            opacity: 1;
        }
        
        @keyframes pulse {
            0%, 100% {
                box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
            }
            50% {
                box-shadow: 0 4px 25px rgba(245, 87, 108, 0.8);
            }
        }
    </style>
</head>
<body>
    <!-- Disclaimer Banner -->
    <div class="disclaimer-banner"><strong>Your voice will be recorded for training purposes.</strong></div>
    <!-- Start Screen (hidden by default) -->
    <section id="start-screen" style="display:none;">
        <div class="top-bar" style="padding: 12px 16px;">
            <div></div>
            <button id="theme-toggle" class="btn btn-ghost" title="Toggle dark mode">ðŸŒ™</button>
        </div>
        <div class="center-hero">
            <div>
                <div class="hero-title">Welcome to Blanca</div>
                <div class="hero-tagline subtle">Please use the microphone to begin your prompt. Below are some of the possible topics you can ask and an example question.</div>
                <div class="start-examples">
                    <div class="start-topics-section">
                        <div class="start-section-title subtle">Suggested topics</div>
                        <div id="start-topics-grid" class="start-topics-grid"></div>
                    </div>
                    <div class="start-example-section">
                        <div class="start-section-title subtle">Example question</div>
                        <div id="start-sample-prompt" class="sample-prompt-text"></div>
                    </div>
                </div>
            </div>
        </div>
        <div class="start-input-bar">
            <div class="start-input">
                <input id="start-query-input" placeholder="Ask a question..." />
                <button id="start-mic-btn" class="icon-btn" title="Voice input">ðŸŽ¤</button>
                <button id="start-send-btn" class="send-btn">Send</button>
            </div>
        </div>
    </section>

    <!-- Main App (two panels) -->
    <div class="main-container" id="main-app">
        <div class="left-panel">
            <div class="top-bar">
                <div class="lhs-intro">
                    <div class="subtle">Participant: <strong id="participant-username">{{ username }}</strong> Â· Sessions completed: <span id="sessions-completed">{{ user_profile.sessions_completed or 0 }}</span> / <span id="session-target">{{ session_target }}</span></div>
                </div>
                <div class="session-controls" style="gap:8px;">
                    <button id="switch-user-btn" class="btn btn-ghost" title="Switch participant">Switch User</button>
                    <button id="theme-toggle" class="btn btn-ghost" title="Toggle dark mode">ðŸŒ™</button>
                </div>
            </div>

            <div id="tools-panel" class="tools-panel">
                <div class="tools-heading">Tools &amp; tips</div>
                <div id="tools-dropdown" class="tools-dropdown">
                    <details id="used-tools-details">
                        <summary>Used tools <span id="used-tools-count" class="count-pill">0</span></summary>
                        <div id="used-tools-list" class="tool-list-grid"></div>
                    </details>
                    <details id="unused-tools-details">
                        <summary>Unused tools <span id="unused-tools-count" class="count-pill">0</span></summary>
                        <div id="unused-tools-list" class="tool-list-grid"></div>
                    </details>
                    
                    <div class="tool-guidance">
                        <div class="tool-guidance-title">Begin your conversation by pressing the blue button on the right hand side </div>
                        <ul class="tool-guidance-list">
                            <li>You may use the example prompt and available tools (please click on the drop-downs above) as inspiration for your prompt</li>
                            <li>Keep each conversation conciseâ€”aim for 3 to 4 turns, the language model is not suited for long, complex instructions (it will not physically do the tasks you request)</li>
                            <li>It's fine if the voice model messes up the transcription. You may start a new session or continue going. The goal is to capture the voice data.</li>
                            <li>If you accidentally said something you wish does not become public, please use our comment feature and we will remove this session from the training data.</li>
                            <li> If at any point you wish to end the session, please press the start new session icon on the top right of your screen</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="followup-panel" class="hidden" style="margin-top: 8px;">
                <div class="section-title">Suggested Follow-ups</div>
                <ul id="followup-list" class="followup-list"></ul>
            </div>

            <div id="related-topics-panel" class="hidden" style="margin-top: 12px;">
                <div class="section-title">Related Topics</div>
                <div id="related-topics-list" class="related-topics-list"></div>
            </div>
        </div>

    <div id="resizer"></div>

    <div class="right-panel">
        <div class="form-container query-form-container">
            <div class="query-header">
                <h3 id="query-interface-title">Query Interface <span id="session-indicator" class="session-indicator">Session {{ session_data.session_number if session_data else 1 }} of {{ session_target }}</span></h3>
                <div id="example-prompt-inline" class="example-prompt-inline subtle"></div>
                <div class="session-controls">
                    <button type="button" id="start-session-btn" class="btn btn-primary">Start New Session</button>
                </div>
            </div>
            <div id="query-conversation" class="query-conversation">
                </div>
            
            <div class="voice-input-container" style="display: flex; flex-direction: column; justify-content: center; align-items: center; padding: 40px; gap: 14px;">
                <div class="mic-instruction subtle">Press the button to start recording.</div>
                <div class="mic-action-row">
                    <button type="button" id="mic-btn" class="mic-btn-large" title="Press to speak">
                        <div class="voice-level-indicator"></div>
                    </button>
                    <button type="button" id="comment-btn" class="comment-btn" title="Add a session comment">Add Comment</button>
                </div>
            </div>
        </div>

        <button id="save-chat-btn" class="btn" style="margin-top:10px;">Save Chat</button>
    </div>
</div>

    <script type="application/json" id="session-config">
        {{ {
            "session": session_data or {},
            "sessionTarget": session_target,
            "sessionsCompleted": user_profile.sessions_completed or 0,
            "username": username
        } | tojson }}
    </script>

    <!-- Floating Tools button -->
    <!-- <button id="tools-fab" class="icon-btn" title="Tools & Raw JSON">ðŸ§°</button> -->

    <!-- Modal for Tools & Raw JSON -->
    <div id="tools-modal" class="modal-backdrop" aria-hidden="true">
        <div class="modal">
            <div class="modal-header">
                <div class="modal-title">Tools & Raw JSON</div>
                <button id="tools-modal-close" class="icon-btn" aria-label="Close">âœ–</button>
            </div>
            <div class="section-title">Capabilities</div>
            <div class="tool-grid" style="margin-bottom:10px;">
                <div class="tool-card"><h4>Travel</h4><p>Flights, hotels, itineraries</p></div>
                <div class="tool-card"><h4>Science</h4><p>Facts, summaries, lookups</p></div>
                <div class="tool-card"><h4>Math</h4><p>Arithmetic, primes, series</p></div>
                <div class="tool-card"><h4>Trivia</h4><p>General knowledge Q&A</p></div>
            </div>
            <div class="section-title inline-controls">
                <span>Raw JSON</span>
                <button id="toggle-raw-btn" class="btn btn-ghost" style="padding: 4px 8px; font-size: 12px;">Show</button>
            </div>
            <pre id="json-content" class="hidden"></pre>
        </div>
    </div>

    <!-- Comment modal -->
    <div id="comment-modal" class="modal-backdrop" aria-hidden="true" role="dialog" aria-modal="true" aria-labelledby="comment-modal-title">
        <div class="modal comment-modal">
            <div class="modal-header">
                <div class="modal-title" id="comment-modal-title">Session Comments</div>
                <button id="comment-modal-close" class="icon-btn" aria-label="Close comment dialog">âœ–</button>
            </div>
            <div class="comment-modal-body">
                <div id="comment-list" class="comment-list"></div>
                <label for="comment-textarea" class="comment-label">Add a new comment</label>
                <textarea id="comment-textarea" class="comment-textarea" rows="4" placeholder="Share feedback, notes, or reminders..."></textarea>
                <div id="comment-error" class="comment-error hidden" role="alert">Please enter a comment before saving.</div>
            </div>
            <div class="comment-modal-actions">
                <button id="comment-cancel-btn" class="btn btn-ghost">Cancel</button>
                <button id="comment-save-btn" class="btn btn-primary">Save Comment</button>
            </div>
        </div>
    </div>
<script>
    // Theme handling
    (function initTheme(){
        const saved = localStorage.getItem('theme') || 'light';
        if (saved === 'dark') document.documentElement.setAttribute('data-theme','dark');
        const buttons = document.querySelectorAll('#theme-toggle');
        const setIcon = (btn) => { if (!btn) return; btn.textContent = document.documentElement.getAttribute('data-theme') === 'dark' ? 'â˜€ï¸' : 'ðŸŒ™'; };
        buttons.forEach(setIcon);
        document.addEventListener('click', (e)=>{
            if (e.target && e.target.id === 'theme-toggle'){
                const cur = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'light';
                const next = cur === 'dark' ? 'light' : 'dark';
                document.documentElement.setAttribute('data-theme', next === 'dark' ? 'dark' : '');
                localStorage.setItem('theme', next);
                document.querySelectorAll('#theme-toggle').forEach(setIcon);
            }
        });
    })();

    const sessionConfigEl = document.getElementById('session-config');
    let sessionConfig = {};
    if (sessionConfigEl) {
        try {
            sessionConfig = JSON.parse(sessionConfigEl.textContent || '{}');
        } catch (err) {
            console.warn('Failed to parse session config payload', err);
        }
    }

    const initialSessionData = sessionConfig.session || {};
    const studySessionTargetDefault = Number(sessionConfig.sessionTarget) || 10;
    const initialSessionsCompleted = Number(sessionConfig.sessionsCompleted) || 0;
    const participantUsernameInitial = (typeof sessionConfig.username === 'string' && sessionConfig.username.trim().length)
        ? sessionConfig.username
        : null;

    let studySessionState = {
        session_id: initialSessionData.session_id || null,
        session_number: initialSessionData.session_number || 1,
        sessions_completed: typeof initialSessionData.sessions_completed === 'number' ? initialSessionData.sessions_completed : initialSessionsCompleted,
        session_target: initialSessionData.session_target || studySessionTargetDefault
    };

    if (!studySessionState.session_number) {
        studySessionState.session_number = studySessionState.sessions_completed + 1;
    }
    if (!studySessionState.session_target) {
        studySessionState.session_target = studySessionTargetDefault;
    }

    function generateStudySessionId() {
        return 'session_' + new Date().toISOString().replace(/[-:]/g, '').replace(/\..+/, '').replace('T', '_');
    }

    let sessionId = studySessionState.session_id || generateStudySessionId();
    let promptNumber = 0;

    const sessionIndicatorEl = document.getElementById('session-indicator');
    const sessionsCompletedEl = document.getElementById('sessions-completed');
    const sessionTargetEl = document.getElementById('session-target');
    const startSessionBtn = document.getElementById('start-session-btn');
    const switchUserBtn = document.getElementById('switch-user-btn');
    const participantUsernameEl = document.getElementById('participant-username');
    const queryInput = document.getElementById('query-input');
    const commentBtn = document.getElementById('comment-btn');
    const commentModal = document.getElementById('comment-modal');
    const commentModalClose = document.getElementById('comment-modal-close');
    const commentTextarea = document.getElementById('comment-textarea');
    const commentSaveBtn = document.getElementById('comment-save-btn');
    const commentCancelBtn = document.getElementById('comment-cancel-btn');
    const commentListEl = document.getElementById('comment-list');
    const commentErrorEl = document.getElementById('comment-error');
    let sessionComments = [];

    function updateSessionDisplays() {
        if (sessionIndicatorEl) {
            sessionIndicatorEl.textContent = `Session ${studySessionState.session_number} of ${studySessionState.session_target}`;
        }
        if (sessionsCompletedEl) {
            sessionsCompletedEl.textContent = studySessionState.sessions_completed;
        }
        if (sessionTargetEl) {
            sessionTargetEl.textContent = studySessionState.session_target;
        }
    }

    updateSessionDisplays();
    if (participantUsernameEl && participantUsernameInitial) {
        participantUsernameEl.textContent = participantUsernameInitial;
    }

    switchUserBtn?.addEventListener('click', () => {
        window.location.href = "{{ url_for('logout') }}";
    });

    function applyStudySessionPayload(sessionPayload) {
        if (!sessionPayload) return;
        studySessionState = {
            session_id: sessionPayload.session_id || null,
            session_number: sessionPayload.session_number || 1,
            sessions_completed: typeof sessionPayload.sessions_completed === 'number' ? sessionPayload.sessions_completed : studySessionState.sessions_completed,
            session_target: sessionPayload.session_target || studySessionState.session_target || studySessionTargetDefault
        };
        if (!studySessionState.session_number) {
            studySessionState.session_number = studySessionState.sessions_completed + 1;
        }
        if (!studySessionState.session_target) {
            studySessionState.session_target = studySessionTargetDefault;
        }
        sessionId = studySessionState.session_id || generateStudySessionId();
        promptNumber = 0;
        updateSessionDisplays();
    }

    function renderSessionComments() {
        if (!commentListEl) return;
        commentListEl.innerHTML = '';
        if (!sessionComments.length) {
            const empty = document.createElement('div');
            empty.className = 'comment-empty';
            empty.textContent = 'No comments added yet.';
            commentListEl.appendChild(empty);
            return;
        }

        sessionComments.forEach((comment, index) => {
            const card = document.createElement('div');
            card.className = 'comment-card';

            const meta = document.createElement('div');
            meta.className = 'comment-meta';
            const when = comment.timestamp ? new Date(comment.timestamp).toLocaleString() : '';
            meta.textContent = `Comment ${index + 1}${when ? ` Â· ${when}` : ''}`;

            const text = document.createElement('div');
            text.className = 'comment-text';
            text.textContent = comment.text;

            card.appendChild(meta);
            card.appendChild(text);
            commentListEl.appendChild(card);
        });
        commentListEl.scrollTop = commentListEl.scrollHeight;
    }

    function updateCommentButton() {
        if (!commentBtn) return;
        const count = sessionComments.length;
        const label = count ? `Add Comment (${count})` : 'Add Comment';
        commentBtn.textContent = label;
        if (count) {
            const helper = `${count} comment${count === 1 ? '' : 's'} saved`;
            commentBtn.setAttribute('aria-label', `Add another comment. ${helper}.`);
            commentBtn.setAttribute('title', `Add another comment (${helper})`);
        } else {
            commentBtn.setAttribute('aria-label', 'Add a session comment');
            commentBtn.setAttribute('title', 'Add a session comment');
        }
        renderSessionComments();
    }

    function openCommentModal() {
        if (!commentModal) return;
        commentModal.classList.add('show');
        commentModal.setAttribute('aria-hidden', 'false');
        if (commentTextarea) {
            commentTextarea.value = '';
            commentTextarea.removeAttribute('aria-invalid');
            setTimeout(() => commentTextarea.focus(), 50);
        }
        if (commentErrorEl) commentErrorEl.classList.add('hidden');
        renderSessionComments();
    }

    function closeCommentModal() {
        if (!commentModal) return;
        commentModal.classList.remove('show');
        commentModal.setAttribute('aria-hidden', 'true');
        if (commentTextarea) {
            commentTextarea.blur();
            commentTextarea.value = '';
            commentTextarea.removeAttribute('aria-invalid');
        }
        if (commentErrorEl) commentErrorEl.classList.add('hidden');
    }

    function handleCommentSave() {
        if (!commentTextarea) return;
        const raw = commentTextarea.value || '';
        const trimmed = raw.trim();
        if (!trimmed) {
            if (commentErrorEl) commentErrorEl.classList.remove('hidden');
            commentTextarea.setAttribute('aria-invalid', 'true');
            commentTextarea.focus();
            return;
        }
        const now = new Date().toISOString();
        sessionComments.push({
            id: (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') ? crypto.randomUUID() : `comment_${Date.now()}`,
            text: trimmed,
            timestamp: now
        });
        if (commentErrorEl) commentErrorEl.classList.add('hidden');
        commentTextarea.value = '';
        commentTextarea.removeAttribute('aria-invalid');
        updateCommentButton();
        commentTextarea.focus();
    }

    function resetConversationForNewSession() {
        const conversation = document.getElementById('query-conversation');
        if (conversation) {
            conversation.innerHTML = '';
        }
        conversationLog.length = 0;
        sessionComments = [];
    closeCommentModal();
        updateCommentButton();
        latestUserPrompt = '';
        updateLatestPromptPanel('');
        renderFollowupExamples([]);
        renderRelatedTopics([]);
        sessionStart = new Date().toISOString();
        promptNumber = 0;
        hasUserPrompted = false;
        if (queryInput) {
            queryInput.value = '';
            queryInput.placeholder = 'Enter your query or use the mic...';
        }
        refreshRandomInstruction();
    }

    async function handleStartNewSession() {
        if (!startSessionBtn) return;
        if (startSessionBtn.disabled) return;
        const originalText = startSessionBtn.textContent;
        startSessionBtn.disabled = true;
        startSessionBtn.textContent = 'Refreshingâ€¦';
        try {
            const response = await fetch('/sessions/advance', { method: 'POST' });
            const data = await response.json();
            if (!response.ok || data.error) {
                throw new Error(data.error || `Request failed (${response.status})`);
            }
            if (data.completed) {
                if (data.redirect_url) {
                    window.location.href = data.redirect_url;
                } else {
                    window.location.href = '/complete';
                }
                return;
            }
            if (data.session) {
                applyStudySessionPayload(data.session);
            }
            if (typeof data.username === 'string' && participantUsernameEl) {
                participantUsernameEl.textContent = data.username;
            }
            resetConversationForNewSession();
        } catch (err) {
            console.error('Failed to advance session', err);
            alert(err.message || 'Unable to start a new session. Please try again.');
        } finally {
            startSessionBtn.disabled = false;
            startSessionBtn.textContent = originalText;
        }
    }

    startSessionBtn?.addEventListener('click', handleStartNewSession);

    // Track conversation log for saving later
    const conversationLog = [];
    let sessionStart = new Date().toISOString();
    let isRecording = false;
    let startSamplePrompt = '';
    let latestUserPrompt = '';
    let lastUserQueryText = '';
    const relatedTopicsState = { topics: [], followUps: [], source: 'none' };
    let keywordTopicIndex = [];
    let keywordTopicItems = [];
    let relatedFetchToken = 0;

    let currentToolsShown = [];
    let currentExamplePrompt = '';
    let currentPromptIdeas = [];

    // Modal handling and raw JSON toggler (modal)
    const toolsFab = document.getElementById('tools-fab');
    const toolsModal = document.getElementById('tools-modal');
    const toolsModalClose = document.getElementById('tools-modal-close');
    const rawPre = document.getElementById('json-content');
    const rawBtn = document.getElementById('toggle-raw-btn');
    if (toolsFab && toolsModal && toolsModalClose) {
        toolsFab.addEventListener('click', ()=>{ toolsModal.classList.add('show'); });
        toolsModalClose.addEventListener('click', ()=>{ toolsModal.classList.remove('show'); });
        toolsModal.addEventListener('click', (e)=>{ if (e.target === toolsModal) toolsModal.classList.remove('show'); });
    }
    if (rawBtn && rawPre) {
        rawBtn.addEventListener('click', ()=>{
            const hidden = rawPre.classList.toggle('hidden');
            rawBtn.textContent = hidden ? 'Show' : 'Hide';
        });
    }

    // Transition from start screen to main app
    const startScreen = document.getElementById('start-screen');
    const mainApp = document.getElementById('main-app');
    function transitionToMain(){
        if (mainApp.classList.contains('hidden')){
            startScreen.classList.add('fade-out');
            setTimeout(()=>{ startScreen.style.display = 'none'; mainApp.classList.remove('hidden'); }, 200);
        }
    }
    // --- Start screen topics and sample prompt ---
    const ALL_TOPICS = [
        { title: 'Travel', desc: 'Flights, hotels, itineraries' },
        { title: 'Science', desc: 'Facts, summaries, lookups' },
        { title: 'Math', desc: 'Arithmetic, primes, series' },
        { title: 'Trivia', desc: 'General knowledge Q&A' },
        { title: 'Shopping', desc: 'Compare prices, find deals' },
        { title: 'Coding', desc: 'APIs, debugging, snippets' },
        { title: 'Health', desc: 'Wellness info, nutrition' },
        { title: 'Finance', desc: 'Budgets, markets, taxes' },
        { title: 'News', desc: 'Headlines, summaries' },
        { title: 'Education', desc: 'Study help, quizzes' },
        { title: 'Sports', desc: 'Scores, schedules, stats' },
        { title: 'Weather', desc: 'Forecasts and advisories' }
    ];
    const SAMPLE_PROMPTS = [
        'Find flights from SFO to NYC next Tuesday under $300 and a 2-night hotel near Times Square.',
        'Summarize the key differences between mitosis and meiosis with examples.',
        'Write a function to compute the nth Fibonacci number and show the first 10.',
        'What is the capital of Brazil and two facts about it?',
        'Compare the MacBook Air M2 vs. Dell XPS 13 for programming and battery life.'
    ];
    const usedToolsDetails = document.getElementById('used-tools-details');
    const unusedToolsDetails = document.getElementById('unused-tools-details');
    const usedToolsListEl = document.getElementById('used-tools-list');
    const unusedToolsListEl = document.getElementById('unused-tools-list');
    const usedToolsCountEl = document.getElementById('used-tools-count');
    const unusedToolsCountEl = document.getElementById('unused-tools-count');
    const randomInstructionEl = document.getElementById('instruction-random-example');
    const examplePromptInline = document.getElementById('example-prompt-inline');

    function refreshRandomInstruction() {
        if (!randomInstructionEl) return;
        const candidates = [];
        const promptSamples = currentPromptIdeas.filter(Boolean);
        if (promptSamples.length) candidates.push(...promptSamples);
        if (currentExamplePrompt) candidates.push(currentExamplePrompt);
        if (!candidates.length) candidates.push(...SAMPLE_PROMPTS);
        const unique = [...new Set(candidates.filter(Boolean))];
        if (!unique.length) return;
        const pick = unique[Math.floor(Math.random() * unique.length)];
        randomInstructionEl.textContent = `Try asking: ${pick}`;
    }

    refreshRandomInstruction();

    const TOPIC_SYNONYM_MAP = {
        physics: ['physics', 'mechanics', 'mechanic', 'quantum', 'gravity', 'force', 'forces', 'energy', 'motion', 'optics', 'electromagnetism', 'relativity', 'thermodynamics', 'waves'],
        search: ['search', 'lookup', 'google', 'bing', 'find', 'discover', 'locate', 'query', 'information', 'research'],
        trivia: ['trivia', 'facts', 'fact', 'quiz', 'questions', 'curiosity', 'knowledge'],
        math: ['math', 'mathematics', 'algebra', 'geometry', 'calculus', 'statistics', 'arithmetic', 'numbers', 'equations'],
        weather: ['weather', 'forecast', 'temperature', 'rain', 'climate', 'conditions', 'storm', 'humidity'],
        finance: ['finance', 'stocks', 'markets', 'budget', 'investing', 'investment', 'money', 'economy', 'economic'],
        coding: ['coding', 'programming', 'debug', 'debugging', 'code', 'software', 'api', 'development', 'compute'],
        travel: ['travel', 'trip', 'journey', 'flights', 'flight', 'hotel', 'vacation', 'itinerary', 'tourism'],
        health: ['health', 'wellness', 'nutrition', 'fitness', 'exercise', 'diet', 'medical', 'medicine'],
        sports: ['sports', 'game', 'games', 'scores', 'athletics', 'leagues', 'teams', 'tournament'],
        news: ['news', 'headlines', 'breaking', 'articles', 'media', 'press', 'reports', 'reporting'],
        education: ['education', 'study', 'learning', 'school', 'teaching', 'quiz', 'lesson', 'class']
    };
    function pickRandom(arr, n){
        const a = arr.slice();
        for (let i=a.length-1;i>0;i--){ const j=Math.floor(Math.random()*(i+1)); [a[i],a[j]]=[a[j],a[i]]; }
        return a.slice(0, n);
    }
    function renderStartTopics(){
        const grid = document.getElementById('start-topics-grid');
        if (grid){
            grid.innerHTML = '';
            pickRandom(ALL_TOPICS, 4).forEach(t => {
                const card = document.createElement('div');
                card.className = 'start-topic-card';
                const title = document.createElement('div');
                title.className = 'start-topic-title';
                title.textContent = t.title;
                const desc = document.createElement('div');
                desc.className = 'start-topic-desc';
                desc.textContent = t.desc;
                card.appendChild(title);
                card.appendChild(desc);
                grid.appendChild(card);
            });
        }
        startSamplePrompt = pickRandom(SAMPLE_PROMPTS, 1)[0] || '';
        const sampleEl = document.getElementById('start-sample-prompt');
        if (sampleEl) sampleEl.textContent = startSamplePrompt ? `Try asking: â€œ${startSamplePrompt}â€` : '';
    }

    function renderToolGroup(listEl, tools, emptyMessage, highlightCards = false) {
        if (!listEl) return;
        listEl.innerHTML = '';
        if (!Array.isArray(tools) || tools.length === 0) {
            const empty = document.createElement('div');
            empty.className = 'subtle';
            empty.style.padding = '8px 4px';
            empty.textContent = emptyMessage;
            listEl.appendChild(empty);
            return;
        }

        tools.forEach((tool) => {
            const toolCard = document.createElement('div');
            toolCard.className = `tool-card${highlightCards ? ' tool-card-highlight' : ''}`;

            const toolName = document.createElement('div');
            toolName.className = 'tool-card-title';
            toolName.textContent = (tool && tool.name) ? tool.name : 'Unnamed tool';

            const toolDesc = document.createElement('div');
            toolDesc.className = 'tool-card-description';
            toolDesc.textContent = (tool && tool.description) ? tool.description : '';

            toolCard.appendChild(toolName);
            toolCard.appendChild(toolDesc);

            const argList = tool && Array.isArray(tool.arguments)
                ? tool.arguments.map(arg => arg.name || '').filter(Boolean)
                : [];
            if (argList.length) {
                const argsEl = document.createElement('div');
                argsEl.className = 'tool-card-args';
                argsEl.textContent = `Args: ${argList.join(', ')}`;
                toolCard.appendChild(argsEl);
            }

            listEl.appendChild(toolCard);
        });
    }

    // Load and display BFCL tools
    function loadTinyAgentData() {
        fetch('/get_tiny_agent_data')
            .then(r => r.json())
            .then(data => {
                const tools = Array.isArray(data.tools) ? data.tools : [];
                const usedSet = new Set((data.usedTools || []).map(name => String(name)));

                currentExamplePrompt = data.exampleQuestion || '';
                const promptIdeas = Array.isArray(data.promptIdeas) ? data.promptIdeas.filter(Boolean) : [];
                currentPromptIdeas = promptIdeas.length ? promptIdeas : (currentExamplePrompt ? [currentExamplePrompt] : []);

                if (examplePromptInline) {
                    examplePromptInline.textContent = currentExamplePrompt ? `Sample prompt: ${currentExamplePrompt}` : '';
                }

                if (!tools.length) {
                    renderToolGroup(usedToolsListEl, [], data.error || 'No tools available right now.', false);
                    renderToolGroup(unusedToolsListEl, [], 'No unused tools to show.', false);
                    if (usedToolsCountEl) usedToolsCountEl.textContent = '0';
                    if (unusedToolsCountEl) unusedToolsCountEl.textContent = '0';
                    if (usedToolsDetails) usedToolsDetails.open = false;
                    if (unusedToolsDetails) unusedToolsDetails.open = false;
                    currentToolsShown = [];
                    refreshRandomInstruction();
                    return;
                }

                const usedTools = tools
                    .filter(tool => usedSet.has(tool.name))
                    .sort((a, b) => a.name.localeCompare(b.name));
                const unusedTools = tools
                    .filter(tool => !usedSet.has(tool.name))
                    .sort((a, b) => a.name.localeCompare(b.name));

                renderToolGroup(usedToolsListEl, usedTools, 'No tools used in this example yet.', true);
                renderToolGroup(unusedToolsListEl, unusedTools, 'All tools have been referenced.', false);

                if (usedToolsCountEl) usedToolsCountEl.textContent = String(usedTools.length);
                if (unusedToolsCountEl) unusedToolsCountEl.textContent = String(unusedTools.length);

                if (usedToolsDetails) usedToolsDetails.open = false;
                if (unusedToolsDetails) unusedToolsDetails.open = usedTools.length === 0 && unusedTools.length > 0;

                currentToolsShown = [...usedTools, ...unusedTools].map(tool => ({
                    name: tool.name,
                    description: tool.description,
                    status: usedSet.has(tool.name) ? 'used' : 'unused'
                }));

                refreshRandomInstruction();
            })
            .catch(err => {
                console.warn('Failed to load Tiny Agent data', err);
                renderToolGroup(usedToolsListEl, [], 'Error loading tools', false);
                renderToolGroup(unusedToolsListEl, [], 'Unable to show additional tools', false);
                if (usedToolsCountEl) usedToolsCountEl.textContent = '0';
                if (unusedToolsCountEl) unusedToolsCountEl.textContent = '0';
                if (usedToolsDetails) usedToolsDetails.open = false;
                if (unusedToolsDetails) unusedToolsDetails.open = false;
                if (examplePromptInline) examplePromptInline.textContent = '';
                currentExamplePrompt = '';
                currentPromptIdeas = [];
                currentToolsShown = [];
                refreshRandomInstruction();
            });
    }

    // Render at load
    renderStartTopics();
    updateCommentButton();
    loadTinyAgentData(); // Load Tiny Agent tools & prompt on page load
    fetch("{{ url_for('static', filename='data/example_functions.json') }}")
        .then(r=>r.json())
        .then(data => { if (data && Array.isArray(data.topics)) buildKeywordTopicIndex(data.topics); })
        .catch(err => console.warn('Failed to load topic catalog', err));
    // Start screen controls (send, mic)
    const startQueryInput = document.getElementById('start-query-input');
    const startSendBtn = document.getElementById('start-send-btn');
    const startMicBtn = document.getElementById('start-mic-btn');

    startSendBtn?.addEventListener('click', ()=>{
        const q = (startQueryInput.value || '').trim(); if (!q) return;
        transitionToMain();
        document.getElementById('query-input').value = q;
        updateLatestPromptPanel(q);
        refreshRelatedSuggestions(q);
        document.querySelector('#query-form button[type="submit"]').click();
        // Clear the start screen input to prevent caching
        startQueryInput.value = '';
        // Reset submission flag
        startIsSubmitting = false;
    });
    
    // Add Enter key support for start screen
    startQueryInput?.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') {
            e.preventDefault();
            const q = (startQueryInput.value || '').trim(); if (!q) return;
            transitionToMain();
            document.getElementById('query-input').value = q;
            updateLatestPromptPanel(q);
            refreshRelatedSuggestions(q);
            document.querySelector('#query-form button[type="submit"]').click();
            // Clear the start screen input to prevent caching
            startQueryInput.value = '';
            // Reset submission flag
            startIsSubmitting = false;
        }
    });

    // Start screen Deepgram streaming functions
    let startSocket, startMicrophone, startProcessor;
    let startHasFinalTranscript = false;
    let startIsSubmitting = false; // Flag to prevent re-recording during submission
    let startVoiceMetadata = {
        words: [],
        utterances: [],
        session_start: new Date().toISOString(),
        total_duration: 0.0
    };
    
    async function startScreenDeepgramStreaming() {
        if (startIsSubmitting) return; // Prevent starting during submission
        isRecording = true;
        startHasFinalTranscript = false;
        startIsSubmitting = false;
        // Reset voice metadata
        startVoiceMetadata = {
            words: [],
            utterances: [],
            session_start: new Date().toISOString(),
            total_duration: 0.0
        };
        startMicBtn.classList.add('recording');
        startQueryInput.placeholder = "ðŸŽ¤ Listening... Speak now!";

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            startMicrophone = stream;

            const wsUrl = (window.location.protocol === 'https:' ? 'wss://' : 'ws://') + window.location.host + '/stt/deepgram';
            startSocket = new WebSocket(wsUrl);

            startSocket.onopen = async () => {
                console.log('Start screen WebSocket connected for Deepgram streaming.');
                try {
                    let mimeType = 'audio/webm;codecs=opus';
                    if (!MediaRecorder.isTypeSupported(mimeType)) mimeType = 'audio/webm';
                    if (!MediaRecorder.isTypeSupported(mimeType)) mimeType = 'audio/ogg;codecs=opus';
                    
                    const mediaRecorder = new MediaRecorder(startMicrophone, { 
                        mimeType: mimeType,
                        audioBitsPerSecond: 16000 
                    });
                    
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && startSocket.readyState === WebSocket.OPEN) {
                            startSocket.send(event.data);
                        }
                    };
                    
                    mediaRecorder.start(250);
                    startProcessor = mediaRecorder;
                    
                } catch (error) {
                    console.error('Error setting up MediaRecorder:', error);
                    startSocket.close();
                }
            };

            startSocket.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);
                    
                    // Capture utterance end events
                    if (data.type === 'UtteranceEnd') {
                        startVoiceMetadata.utterances.push({
                            type: 'utterance_end',
                            timestamp: new Date().toISOString()
                        });
                        console.log('[Start screen] Utterance ended');
                    }
                    
                    if (data.transcript) {
                        startQueryInput.value = data.transcript;
                        console.log('[Start screen] Transcript:', data.transcript, 'Final:', !data.interim);
                        
                        // Extract word-level metadata from backend message
                        if (!data.interim && data.words && Array.isArray(data.words)) {
                            console.log('[Start screen] Got word timestamps:', data.words);
                            for (const word of data.words) {
                                startVoiceMetadata.words.push({
                                    word: word.word || '',
                                    start: word.start || 0.0,
                                    end: word.end || 0.0,
                                    confidence: word.confidence || 0.0,
                                    punctuated_word: word.punctuated_word || word.word || ''
                                });
                                if (word.end > startVoiceMetadata.total_duration) {
                                    startVoiceMetadata.total_duration = word.end;
                                }
                            }
                        }
                        
                        if (data.interim) {
                            startQueryInput.style.fontStyle = 'italic';
                            startQueryInput.style.opacity = '0.8';
                        } else {
                            startQueryInput.style.fontStyle = 'normal';
                            startQueryInput.style.opacity = '1';
                            startHasFinalTranscript = true;
                        }
                    } else if (data.llm_response) {
                        // Ignore LLM interjections on start screen
                        console.log('[Start screen] Ignoring LLM interjection:', data.llm_response);
                    } else if (data.error) {
                        console.error('WebSocket error:', data.error);
                        alert('Streaming error: ' + data.error);
                    } else if (data.status) {
                        console.log('WebSocket status:', data.message);
                    }
                } catch (e) {
                    console.error('Error parsing WebSocket message:', e);
                }
            };

            startSocket.onclose = (event) => {
                console.log('Start screen WebSocket closed:', event.code, event.reason);
            };
            
            startSocket.onerror = (err) => {
                console.error('Start screen WebSocket error:', err);
                if (isRecording) {
                    stopStartScreenDeepgramStreaming();
                }
            };

        } catch (err) {
            console.error('Start screen mic/WebSocket error:', err);
            alert('Unable to access microphone or connect to streaming service: ' + err.message);
            await stopStartScreenDeepgramStreaming();
        }
    }

    async function stopStartScreenDeepgramStreaming() {
        if (!isRecording) return; // Already stopped
        
        console.log('[Start screen] Stopping, has final transcript:', startHasFinalTranscript, 'Input value:', startQueryInput.value);
        console.log('[Start screen] Voice metadata collected:', startVoiceMetadata);
        
        // Stop audio immediately
        if (startProcessor && startProcessor.stop) startProcessor.stop();
        if (startMicrophone) startMicrophone.getTracks().forEach(track => track.stop());
        isRecording = false;
        startIsSubmitting = true; // Lock to prevent re-recording
        startMicBtn.classList.remove('recording');
        startQueryInput.placeholder = "Finalizing...";
        startQueryInput.style.fontStyle = 'normal';
        startQueryInput.style.opacity = '1';
        
        // Brief wait for final transcript, then submit
        setTimeout(() => {
            if (startSocket) startSocket.close();
            startSocket = startMicrophone = startProcessor = null;
            
            const text = startQueryInput.value.trim();
            console.log('[Start screen] Ready to submit, text:', text);
            
            // Save voice metadata to backend
            if (text && startVoiceMetadata.words.length > 0) {
                console.log('[Start screen] Saving voice metadata...');
                fetch('/save_voice_metadata', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        transcript: text,
                        metadata: startVoiceMetadata
                    })
                }).then(r => r.json())
                  .then(d => console.log('[Start screen] Voice metadata saved:', d))
                  .catch(err => console.error('[Start screen] Failed to save metadata:', err));
            }
            
            if (text) {
                startQueryInput.placeholder = "Submitting...";
                startSendBtn.click();
            } else {
                startQueryInput.placeholder = "Ask a question...";
                startIsSubmitting = false; // Reset if no submission
            }
        }, 500); // Reduced delay
    }
    
    // Start screen chunked recording functions
    async function startScreenChunkedRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mimeType = chooseAudioMime();
            mediaRecorder = mimeType ? new MediaRecorder(stream, { mimeType }) : new MediaRecorder(stream);
            const res = await fetch('/stt/start', { method: 'POST' });
            const data0 = await res.json(); 
            if (!res.ok || !data0.stt_sid) throw new Error(data0.error || 'Failed to start STT session');
            sttSid = data0.stt_sid; 
            isRecording = true; 
            startMicBtn.classList.add('recording');
            startQueryInput.placeholder = "Recording... Click mic to stop.";
            
            mediaRecorder.addEventListener('dataavailable', async (e) => {
                if (e.data && e.data.size > 0 && isRecording) {
                    const fd = new FormData();
                    const ext = extForMime(mediaRecorder.mimeType);
                    const file = new File([e.data], `chunk_${Date.now()}.${ext}`, { type: mediaRecorder.mimeType });
                    fd.append('audio', file);
                    try { await fetch('/stt/chunk', { method: 'POST', body: fd }); } catch {}
                }
            });
            mediaRecorder.start(2000);
        } catch (err) { 
            alert('Unable to access microphone: ' + err.message); 
        }
    }
    
    async function stopStartScreenChunkedRecording() {
        if (!mediaRecorder || mediaRecorder.state === 'inactive') return;
        isRecording = false; 
        mediaRecorder.stop(); 
        mediaRecorder.stream.getTracks().forEach(t=>t.stop());
        startMicBtn.classList.remove('recording');
        startQueryInput.placeholder = "Finalizing transcription...";
        
        try { 
            const res2 = await fetch('/stt/stop', { method: 'POST' }); 
            const data = await res2.json(); 
            if (data.text) { 
                startQueryInput.value = data.text;
                // Auto-submit after transcription completes
                startSendBtn.click();
            } else if (data.error) {
                console.error('STT error:', data.error);
                alert('Transcription failed: ' + data.error);
            }
        } catch (err) {
            console.error('Failed to stop STT session:', err);
            alert('An error occurred while finalizing transcription.');
        } finally {
            startQueryInput.placeholder = "Ask a question...";
            mediaRecorder = null;
            sttSid = null;
        }
    }
    
    // Start screen mic button - checks backend and routes appropriately
    startMicBtn?.addEventListener('click', async ()=>{
        if (sttBackend === 'deepgram_streaming') {
            if (isRecording) await stopStartScreenDeepgramStreaming(); 
            else await startScreenDeepgramStreaming();
        } else {
            if (isRecording) await stopStartScreenChunkedRecording(); 
            else await startScreenChunkedRecording();
        }
    });
    // --- Voice Input: Conditional logic for STT backend ---
    const sttBackend = '{{ stt_backend }}';
    const micBtn = document.getElementById('mic-btn');
    let hasUserPrompted = false; // Track if user has made their first prompt

    // --- Session tracking for organized recordings ---
    // sessionId and promptNumber defined earlier via study session state
    // --- Logic for Deepgram Streaming STT ---
    let socket;
    let microphone;
    let processor;

    let currentTranscript = ''; // Track current transcript
    let liveUserMessage = null; // Track the live user message element
    let audioRecorder = null; // MediaRecorder for saving audio
    let audioChunks = []; // Store audio chunks
    let currentRecordingPath = null; // Track current recording path
    let intentionalClose = false; // Track if connection close is intentional
    let recordingStartTime = null; // Track when recording started
    let recordingEndTime = null; // Track when recording ended
    
    async function startDeepgramStreaming() {
        console.log('Starting Deepgram streaming...');
        promptNumber++; // Increment prompt number for this session
        isRecording = true;
        micBtn.classList.add('recording');
        currentTranscript = '';
        audioChunks = []; // Reset audio chunks
        currentRecordingPath = null;
        intentionalClose = false; // Reset flag for new connection
        recordingStartTime = new Date().toISOString(); // Capture start time
        recordingEndTime = null;
        console.log(`Recording prompt ${promptNumber} in ${sessionId}`);
        
        // Create a live user message in the conversation
        const conversation = document.getElementById('query-conversation');
        liveUserMessage = document.createElement('div');
        liveUserMessage.className = 'message-user';
        liveUserMessage.style.opacity = '0.7'; // Dimmed while recording
        liveUserMessage.style.fontStyle = 'italic';
        liveUserMessage.textContent = 'Listening...';
        conversation.appendChild(liveUserMessage);
        conversation.scrollTop = conversation.scrollHeight;

        try {
            console.log('Requesting microphone access...');
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            microphone = stream;
            console.log('Microphone access granted');
            
            // Setup MediaRecorder to capture audio for saving
            const mimeType = 'audio/webm;codecs=opus';
            audioRecorder = new MediaRecorder(stream, { mimeType });
            audioRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    audioChunks.push(e.data);
                }
            };
            audioRecorder.start(100); // Collect chunks every 100ms
            console.log('Audio recording started');

            // Setup Web Audio API for voice level detection
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const micSource = audioContext.createMediaStreamSource(stream);
            
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.5;  // Less smoothing for faster response
            micSource.connect(analyser);
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
            
            // Animation loop to update voice level indicator
            let animationFrameId;
            function updateVoiceLevel() {
                if (!isRecording) {
                    cancelAnimationFrame(animationFrameId);
                    return;
                }
                
                analyser.getByteFrequencyData(dataArray);
                
                // Calculate average volume with emphasis on voice frequencies
                let sum = 0;
                const voiceRangeStart = Math.floor(dataArray.length * 0.1);
                const voiceRangeEnd = Math.floor(dataArray.length * 0.6);
                for (let i = voiceRangeStart; i < voiceRangeEnd; i++) {
                    sum += dataArray[i];
                }
                const average = sum / (voiceRangeEnd - voiceRangeStart);
                
                // Amplify and map volume with non-linear scaling for better sensitivity
                const normalized = Math.min(average / 128, 1.0);  // Normalize to 0-1 (more sensitive)
                const amplified = Math.pow(normalized, 0.7);  // Exponential curve
                const scale = 0.3 + (amplified * 1.4);  // Range from 0.3 to 1.7
                
                voiceLevelIndicator.style.transform = `translate(-50%, -50%) scale(${scale})`;
                
                animationFrameId = requestAnimationFrame(updateVoiceLevel);
            }
            
            updateVoiceLevel();

            const wsUrl = (window.location.protocol === 'https:' ? 'wss://' : 'ws://') + window.location.host + '/stt/deepgram';
            console.log('Connecting to WebSocket:', wsUrl);
            socket = new WebSocket(wsUrl);

            socket.onopen = async () => {
                console.log('âœ“ WebSocket connected for Deepgram streaming.');
                try {
                    // Use MediaRecorder with a more compatible format
                    let mimeType = 'audio/webm;codecs=opus';
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/webm';
                    }
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/ogg;codecs=opus';
                    }
                    
                    const mediaRecorder = new MediaRecorder(microphone, { 
                        mimeType: mimeType,
                        audioBitsPerSecond: 16000 
                    });
                    
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && socket.readyState === WebSocket.OPEN) {
                            console.log('Sending audio chunk, size:', event.data.size);
                            socket.send(event.data);
                        }
                    };
                    
                    mediaRecorder.onerror = (event) => {
                        console.error('MediaRecorder error:', event.error);
                    };
                    
                    mediaRecorder.start(250); // Send chunks every 250ms for better stability and less load
                    processor = mediaRecorder; // Store reference for cleanup
                    
                } catch (error) {
                    console.error('Error setting up MediaRecorder:', error);
                    socket.close();
                }
            };

            socket.onmessage = (event) => {
                console.log('Received WebSocket message:', event.data);
                try {
                    const data = JSON.parse(event.data);
                    
                    if (data.transcript) {
                        // Real-time transcript updates
                        currentTranscript = data.transcript;
                        console.log('Real-time transcript:', data.transcript, data.interim ? '(interim)' : '(final)');
                        
                        // Update live user message in conversation
                        if (liveUserMessage && data.transcript.trim()) {
                            liveUserMessage.textContent = data.transcript;
                            liveUserMessage.style.opacity = data.interim ? '0.7' : '0.85';
                            liveUserMessage.style.fontStyle = data.interim ? 'italic' : 'normal';
                            
                            // Auto-scroll to keep message visible
                            const conversation = document.getElementById('query-conversation');
                            conversation.scrollTop = conversation.scrollHeight;
                        }
                        
                    } else if (data.llm_response) {
                        // LLM responded (either manually triggered or automatic)
                        const responseType = data.type === 'manual_submit' ? 'Manual submit' : 'Auto interjection';
                        console.log(`${responseType} - LLM response:`, data.llm_response);
                        console.log('User transcript:', data.user_transcript);
                        
                        const conversation = document.getElementById('query-conversation');
                        
                        // Remove the live user message if it exists
                        if (liveUserMessage && liveUserMessage.parentNode) {
                            liveUserMessage.remove();
                            liveUserMessage = null;
                        }
                        
                        // Add the final user message (plain text, no pause markers)
                        if (data.user_transcript && data.user_transcript.trim()) {
                            const userMessage = document.createElement('div');
                            userMessage.className = 'message-user';
                            userMessage.textContent = data.user_transcript.trim();
                            userMessage.style.opacity = '1'; // Full opacity
                            userMessage.style.fontStyle = 'normal'; // Not italic
                            conversation.appendChild(userMessage);
                            
                            // Hide example question after first prompt
                            if (!hasUserPrompted) {
                                hasUserPrompted = true;
                                const examplePanel = document.getElementById('example-question-panel');
                                if (examplePanel) examplePanel.style.display = 'none';
                            }
                        }
                        
                        // Then add LLM response
                        const botMessage = document.createElement('div');
                        botMessage.className = 'message-bot';
                        botMessage.textContent = data.llm_response;
                        conversation.appendChild(botMessage);
                        conversation.scrollTop = conversation.scrollHeight;
                        
                        // Clear the transcript
                        currentTranscript = '';
                        
                        // Save audio recording if we have one and a recording_path
                        if (data.recording_path && audioChunks.length > 0) {
                            console.log(`Saving audio recording for ${data.recording_path}...`);
                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                            const formData = new FormData();
                            formData.append('audio', audioBlob, 'audio.webm');
                            formData.append('recording_path', data.recording_path);
                            
                            fetch('/save_audio_recording', {
                                method: 'POST',
                                body: formData
                            })
                            .then(r => r.json())
                            .then(result => {
                                console.log('âœ“ Audio recording saved:', result);
                                audioChunks = []; // Clear chunks after saving
                            })
                            .catch(err => console.error('Failed to save audio recording:', err));
                        }
                        
                        // If this was a manual submit, close the WebSocket connection
                        if (data.type === 'manual_submit') {
                            console.log('Received LLM response for manual submit, closing connection');
                            intentionalClose = true; // Mark as intentional before closing
                            if (socket) {
                                socket.close();
                                socket = null;
                            }
                        }
                        
                    } else if (data.error) {
                        console.error('WebSocket error:', data.error);
                        alert('Streaming error: ' + data.error);
                    } else if (data.status) {
                        console.log('WebSocket status:', data.message);
                    }
                } catch (e) {
                    console.error('Error parsing WebSocket message:', e);
                }
            };

            socket.onclose = (event) => {
                console.log('WebSocket closed:', event.code, event.reason);
                if (!intentionalClose) {
                    console.warn('âš ï¸ Unexpected WebSocket close');
                }
                isRecording = false;
                micBtn.classList.remove('recording');
                if (processor && processor.stop) processor.stop();
                if (microphone) microphone.getTracks().forEach(track => track.stop());
            };
            socket.onerror = (err) => {
                console.error('âŒ WebSocket error:', err);
                if (!intentionalClose) {
                    alert('Connection error. Please try again.');
                }
            };

        } catch (err) {
            console.error('âŒ Mic/WebSocket error:', err);
            if (err.name === 'NotAllowedError') {
                alert('Microphone access denied. Please allow microphone access in your browser settings.');
            } else {
                alert('Unable to access microphone: ' + err.message);
            }
            isRecording = false;
            micBtn.classList.remove('recording');
            
            // Stop audio recorder on error
            if (audioRecorder && audioRecorder.state === 'recording') {
                audioRecorder.stop();
            }
            audioRecorder = null;
            audioChunks = [];
            
            // Remove live user message on error
            if (liveUserMessage && liveUserMessage.parentNode) {
                liveUserMessage.remove();
                liveUserMessage = null;
            }
        }
    }

    async function stopDeepgramStreaming() {
        console.log('User manually stopping recording...');
        intentionalClose = true; // Mark this as an intentional close
        recordingEndTime = new Date().toISOString(); // Capture end time
        
        // Stop audio recorder
        if (audioRecorder && audioRecorder.state === 'recording') {
            audioRecorder.stop();
            console.log('Audio recording stopped');
        }
        
        // Stop microphone and recording but keep WebSocket open for LLM response
        if (processor && processor.stop) processor.stop();
        if (microphone) microphone.getTracks().forEach(track => track.stop());
        isRecording = false;
        micBtn.classList.remove('recording');
        
        // Reset voice level indicator
        const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
        if (voiceLevelIndicator) {
            voiceLevelIndicator.style.transform = 'translate(-50%, -50%) scale(0.3)';
        }
        
        // Make the live user message solid (not italic) while waiting for LLM response
        if (liveUserMessage) {
            liveUserMessage.style.opacity = '1';
            liveUserMessage.style.fontStyle = 'normal';
        }
        
        microphone = processor = audioRecorder = null;
        
        // Send finalize message to trigger LLM response with complete transcript
        // Keep socket open to receive the response
        if (socket && socket.readyState === WebSocket.OPEN) {
            socket.send(JSON.stringify({ 
                action: 'finalize',
                session_id: sessionId,
                prompt_number: promptNumber,
                recording_start_time: recordingStartTime,
                recording_end_time: recordingEndTime,
                tools_shown: currentToolsShown,
                example_prompt_shown: currentExamplePrompt,
                prompt_ideas: currentPromptIdeas,
                is_first_prompt_in_session: (promptNumber === 1)
            }));
            console.log(`Sent finalize message for ${sessionId}/prompt_${promptNumber} - keeping connection open for LLM response`);
        }
        
        // Note: Socket will be closed after receiving LLM response (handled in onmessage)
    }

    // --- Logic for chunked recording (Whisper/Gemini) ---
    let mediaRecorder = null;
    let sttSid = null;

    function chooseAudioMime() {
        const options = ['audio/webm;codecs=opus', 'audio/webm', 'audio/ogg;codecs=opus', 'audio/ogg'];
        for (const t of options) {
            if (window.MediaRecorder && MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t)) return t;
        }
        return '';
    }

    function extForMime(m) {
        if (!m) return 'webm';
        if (m.includes('ogg')) return 'ogg';
        return 'webm';
    }

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mimeType = chooseAudioMime();
            mediaRecorder = mimeType ? new MediaRecorder(stream, { mimeType }) : new MediaRecorder(stream);
            
            // Setup Web Audio API for voice level detection
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const micSource = audioContext.createMediaStreamSource(stream);
            
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.5;  // Less smoothing for faster response
            micSource.connect(analyser);
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
            
            // Animation loop to update voice level indicator
            let animationFrameId;
            function updateVoiceLevel() {
                if (!isRecording) {
                    cancelAnimationFrame(animationFrameId);
                    return;
                }
                
                analyser.getByteFrequencyData(dataArray);
                
                // Calculate average volume with emphasis on voice frequencies
                let sum = 0;
                const voiceRangeStart = Math.floor(dataArray.length * 0.1);
                const voiceRangeEnd = Math.floor(dataArray.length * 0.6);
                for (let i = voiceRangeStart; i < voiceRangeEnd; i++) {
                    sum += dataArray[i];
                }
                const average = sum / (voiceRangeEnd - voiceRangeStart);
                
                // Amplify and map volume with non-linear scaling for better sensitivity
                const normalized = Math.min(average / 128, 1.0);  // Normalize to 0-1 (more sensitive)
                const amplified = Math.pow(normalized, 0.7);  // Exponential curve
                const scale = 0.3 + (amplified * 1.4);  // Range from 0.3 to 1.7
                
                voiceLevelIndicator.style.transform = `translate(-50%, -50%) scale(${scale})`;
                
                animationFrameId = requestAnimationFrame(updateVoiceLevel);
            }
            
            updateVoiceLevel();
            
            const res = await fetch('/stt/start', { method: 'POST' });
            const data0 = await res.json();
            if (!res.ok || !data0.stt_sid) throw new Error(data0.error || 'Failed to start STT session');
            sttSid = data0.stt_sid;

            mediaRecorder.addEventListener('dataavailable', async (e) => {
                if (e.data && e.data.size > 0 && isRecording) {
                    const fd = new FormData();
                    const ext = extForMime(mediaRecorder.mimeType);
                    const file = new File([e.data], `chunk_${Date.now()}.${ext}`, { type: mediaRecorder.mimeType });
                    fd.append('audio', file);
                    try { await fetch('/stt/chunk', { method: 'POST', body: fd }); } catch (err) { console.error('Chunk upload failed', err); }
                }
            });

            mediaRecorder.start(2000);
            isRecording = true;
            micBtn.classList.add('recording');
        } catch (err) {
            console.error('Mic error:', err);
            alert('Unable to access microphone: ' + err.message);
        }
    }

    async function stopRecording() {
        if (!mediaRecorder || mediaRecorder.state === 'inactive') return;
        isRecording = false;
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(t => t.stop());
        micBtn.classList.remove('recording');
        
        // Reset voice level indicator
        const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
        if (voiceLevelIndicator) {
            voiceLevelIndicator.style.transform = 'translate(-50%, -50%) scale(0.3)';
        }

        try {
            const res = await fetch('/stt/stop', { method: 'POST' });
            const data = await res.json();
            if (data.text) {
                // Display user message
                const conversation = document.getElementById('query-conversation');
                const userMessage = document.createElement('div');
                userMessage.className = 'message-user';
                userMessage.textContent = data.text;
                conversation.appendChild(userMessage);
                conversation.scrollTop = conversation.scrollHeight;
                
                // Hide example question after first prompt
                if (!hasUserPrompted) {
                    hasUserPrompted = true;
                    const examplePanel = document.getElementById('example-question-panel');
                    if (examplePanel) examplePanel.style.display = 'none';
                }
                
                // Send query to backend
                const queryData = new FormData();
                queryData.append('query', data.text);
                
                fetch('/query', {
                    method: 'POST',
                    body: queryData
                })
                .then(response => response.json())
                .then(responseData => {
                    const botMessage = document.createElement('div');
                    botMessage.className = 'message-bot';
                    botMessage.textContent = responseData.response || (responseData.error ? ('Error: ' + responseData.error) : '');
                    conversation.appendChild(botMessage);
                    conversation.scrollTop = conversation.scrollHeight;
                })
                .catch(error => {
                    console.error('Query error:', error);
                });
            } else if (data.error) {
                console.error('STT error:', data.error);
                alert('Transcription failed: ' + data.error);
            }
        } catch (e) {
            console.error('Failed to stop STT session:', e);
            alert('An error occurred while finalizing transcription.');
        } finally {
            mediaRecorder = null;
            sttSid = null;
        }
    }

    // Main mic button event listener
    micBtn?.addEventListener('click', async () => {
        if (sttBackend === 'deepgram_streaming') {
            if (isRecording) await stopDeepgramStreaming(); else await startDeepgramStreaming();
        } else {
            if (isRecording) await stopRecording(); else await startRecording();
        }
    });

    commentBtn?.addEventListener('click', openCommentModal);
    commentModalClose?.addEventListener('click', closeCommentModal);
    commentCancelBtn?.addEventListener('click', closeCommentModal);
    commentModal?.addEventListener('click', (event) => {
        if (event.target === commentModal) {
            closeCommentModal();
        }
    });
    commentSaveBtn?.addEventListener('click', handleCommentSave);
    commentTextarea?.addEventListener('keydown', (event) => {
        if ((event.ctrlKey || event.metaKey) && event.key === 'Enter') {
            event.preventDefault();
            handleCommentSave();
        }
    });
    commentTextarea?.addEventListener('input', () => {
        if (commentErrorEl) commentErrorEl.classList.add('hidden');
        commentTextarea.removeAttribute('aria-invalid');
    });
    document.addEventListener('keydown', (event) => {
        if (event.key === 'Escape' && commentModal?.classList.contains('show')) {
            closeCommentModal();
        }
    });

    // Save chat button handler
        document.getElementById('save-chat-btn').addEventListener('click', function() {
            const payload = {
                sessionInfo: {
                    sessionId: crypto.randomUUID(),
                    userId: 'anonymous',
                    startTimestamp: sessionStart,
                    endTimestamp: new Date().toISOString(),
                    llmModel: 'gemini-1.5-flash-latest'
                },
                context: {
                    initialContent: latestUserPrompt || '',
                    finalContent: conversationLog.length ? conversationLog[conversationLog.length - 1].content : ''
                },
                conversationLog: conversationLog,
                evaluation: {
                    surveyResponses: {},
                    userComments: '',
                    sessionComments: sessionComments.map(comment => ({
                        id: comment.id,
                        text: comment.text,
                        timestamp: comment.timestamp
                    }))
                }
            };
            fetch('/save_chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            })
            .then(r => r.json())
            .then(d => {
                if (d.error) {
                    alert('Failed to save: ' + d.error);
                } else {
                    alert('Saved: ' + d.dirName);
                }
            })
            .catch(err => {
                alert('Save error: ' + err);
            });
        });

        // --- Similarity helpers (trigram + cosine) ---
        function trigramVector(text){
            const v = new Map();
            const t = (text || '').toLowerCase();
            for (let i=0;i<t.length-2;i++){
                const tri = t.slice(i,i+3);
                v.set(tri, (v.get(tri)||0)+1);
            }
            return v;
        }
        function wordVector(text){
            const v = new Map();
            const tokens = (text||'').toLowerCase().split(/[^a-z0-9]+/).filter(Boolean);
            for (const tok of tokens){ v.set(tok, (v.get(tok)||0)+1); }
            return v;
        }
        function cosineSim(v1, v2){
            if (!v1 || !v2) return 0;
            let dot=0, norm1=0, norm2=0;
            for (const [,w] of v1) norm1 += w*w;
            for (const [,w] of v2) norm2 += w*w;
            const smaller = v1.size < v2.size ? v1 : v2;
            const other = smaller===v1 ? v2 : v1;
            for (const [k,w] of smaller){ const w2 = other.get(k)||0; if (w2) dot += w*w2; }
            if (!norm1 || !norm2) return 0;
            return dot / (Math.sqrt(norm1)*Math.sqrt(norm2));
        }
        function buildKeywordTopicIndex(topics){
            if (!Array.isArray(topics)) return;
            keywordTopicItems = topics.slice();
            keywordTopicIndex = keywordTopicItems.map(t => {
                const text = [t.title, t.description, ...(t.functions||[]).map(f=>`${f.name} ${f.description}`)].join(' ').toLowerCase();
                const synonyms = new Set((TOPIC_SYNONYM_MAP[t.id] || []).map(s => s.toLowerCase()));
                const tokens = new Set(text.split(/[^a-z0-9]+/).filter(Boolean));
                synonyms.forEach(s => tokens.add(s));
                return {
                    topic: t,
                    triVector: trigramVector(text),
                    wordVector: wordVector(text),
                    tokens,
                    synonyms
                };
            });
        }

        function keywordTopicFallback(prompt){
            const q = (prompt || '').toLowerCase();
            if (!q || !keywordTopicIndex.length) return keywordTopicItems.slice(0, 3).map(t => ({ title: t.title, description: t.description || '' }));
            const qTri = trigramVector(q);
            const qWord = wordVector(q);
            const qTokens = new Set(q.split(/[^a-z0-9]+/).filter(Boolean));
            const scored = keywordTopicIndex.map(entry => {
                const tri = cosineSim(qTri, entry.triVector);
                const word = cosineSim(qWord, entry.wordVector);
                let boost = 0;
                qTokens.forEach(tok => {
                    if (entry.tokens.has(tok)) boost += 0.04;
                    if (entry.synonyms.has(tok)) boost += 0.08;
                });
                return { entry, score: (0.6 * tri) + (0.4 * word) + boost };
            }).sort((a,b)=>b.score - a.score);
            const filtered = scored.filter(s => s.score > 0.01).slice(0, 3);
            const picks = filtered.length ? filtered : scored.slice(0, 3);
            const mapped = picks.map(item => ({
                title: item.entry.topic.title,
                description: item.entry.topic.description || ''
            })).filter(t => t.title);
            if (!mapped.length){
                return ALL_TOPICS.slice(0, 3).map(t => ({ title: t.title, description: t.desc || '' }));
            }
            return mapped;
        }

        function updateLatestPromptPanel(text){
            if (typeof text === 'string') {
                latestUserPrompt = text.trim();
            }
            const panel = document.getElementById('latest-prompt-panel');
            const content = document.getElementById('latest-prompt-content');
            if (!panel || !content) return;
            if (latestUserPrompt){
                content.textContent = latestUserPrompt;
                panel.classList.remove('hidden');
            } else {
                content.textContent = '';
                panel.classList.add('hidden');
            }
        }

        function renderFollowupExamples(followUps){
            const panel = document.getElementById('followup-panel');
            const list = document.getElementById('followup-list');
            if (!panel || !list) return;
            list.innerHTML = '';
            const items = Array.isArray(followUps) ? followUps.filter(Boolean).map(f => String(f).trim()).filter(Boolean).slice(0, 2) : [];
            if (!items.length){
                panel.classList.add('hidden');
                return;
            }
            for (const q of items){
                const li = document.createElement('li');
                li.textContent = q;
                list.appendChild(li);
            }
            panel.classList.remove('hidden');
        }

        function renderRelatedTopics(topics){
            const panel = document.getElementById('related-topics-panel');
            const list = document.getElementById('related-topics-list');
            if (!panel || !list) return;
            list.innerHTML = '';
            const items = Array.isArray(topics) ? topics.filter(Boolean).slice(0, 3) : [];
            if (!items.length){
                panel.classList.add('hidden');
                return;
            }
            items.forEach(t => {
                const item = document.createElement('div');
                item.className = 'related-topic-item';
                const title = document.createElement('div');
                title.className = 'related-topic-title';
                title.textContent = t.title || '';
                const desc = document.createElement('div');
                desc.className = 'related-topic-desc';
                desc.textContent = t.description || '';
                item.appendChild(title);
                if (desc.textContent) item.appendChild(desc);
                list.appendChild(item);
            });
            panel.classList.remove('hidden');
        }

        async function refreshRelatedSuggestions(prompt){
            const trimmed = (prompt || '').trim();
            const requestToken = ++relatedFetchToken;
            if (!trimmed){
                relatedTopicsState.topics = [];
                relatedTopicsState.followUps = [];
                relatedTopicsState.source = 'none';
                renderRelatedTopics([]);
                renderFollowupExamples([]);
                return;
            }
            try {
                const res = await fetch('/related_topics', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt: trimmed })
                });
                if (!res.ok) throw new Error(`HTTP ${res.status}`);
                const data = await res.json();
                if (requestToken !== relatedFetchToken) return;
                relatedTopicsState.topics = Array.isArray(data.topics) ? data.topics : [];
                relatedTopicsState.followUps = Array.isArray(data.followUps) ? data.followUps : [];
                relatedTopicsState.source = data.source || 'unknown';
                if (!relatedTopicsState.topics.length){
                    relatedTopicsState.topics = keywordTopicFallback(trimmed);
                }
                renderRelatedTopics(relatedTopicsState.topics);
                renderFollowupExamples(relatedTopicsState.followUps);
            } catch (err) {
                console.error('Failed to fetch related topics', err);
                if (requestToken !== relatedFetchToken) return;
                relatedTopicsState.topics = keywordTopicFallback(trimmed);
                relatedTopicsState.followUps = [];
                relatedTopicsState.source = 'fallback-client';
                renderRelatedTopics(relatedTopicsState.topics);
                renderFollowupExamples([]);
            }
        }

        // Draggable resizer
        const resizer = document.getElementById('resizer');
        const leftPanel = document.querySelector('.left-panel');
        const rightPanel = document.querySelector('.right-panel');

        const resize = (e) => {
            const isHorizontal = window.innerWidth > 768;
            if (isHorizontal) {
                const newWidth = e.clientX;
                if (newWidth > 200 && newWidth < window.innerWidth - 200) {
                    leftPanel.style.flexBasis = `${newWidth}px`;
                }
            } else {
                const newHeight = e.clientY;
                if (newHeight > 100 && newHeight < window.innerHeight - 100) {
                    leftPanel.style.flexBasis = `${newHeight}px`;
                    leftPanel.style.height = `${newHeight}px`;
                }
            }
        };

        resizer.addEventListener('mousedown', (e) => {
            e.preventDefault();
            document.addEventListener('mousemove', resize);
            document.addEventListener('mouseup', () => {
                document.removeEventListener('mousemove', resize);
            });
        });
</script>
</body>
</html>