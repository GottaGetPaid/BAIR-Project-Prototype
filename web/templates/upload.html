<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
    <style>
        .mic-btn-large {
            position: relative;
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: linear-gradient(135deg, #60a5fa 0%, #3b82f6 100%);
            border: none;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(59, 130, 246, 0.4);
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        /* Dark mode styling */
        @media (prefers-color-scheme: dark) {
            .mic-btn-large {
                background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
                box-shadow: 0 4px 15px rgba(59, 130, 246, 0.5);
            }
        }
        
        .mic-btn-large:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(59, 130, 246, 0.6);
        }
        
        .mic-btn-large:active {
            transform: scale(0.95);
        }
        
        .mic-btn-large.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }
        
        .voice-level-indicator {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 60%;
            height: 60%;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.4);
            opacity: 0;
            transition: transform 0.03s ease-out, opacity 0.3s ease;
            transform: translate(-50%, -50%) scale(0.3);
            transform-origin: center;
        }
        
        .mic-btn-large.recording .voice-level-indicator {
            opacity: 1;
        }
        
        @keyframes pulse {
            0%, 100% {
                box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
            }
            50% {
                box-shadow: 0 4px 25px rgba(245, 87, 108, 0.8);
            }
        }
    </style>
</head>
<body>
    <!-- Disclaimer Banner -->
    <div class="disclaimer-banner"><strong>Your voice will be recorded for training purposes.</strong></div>
    <!-- Start Screen (hidden by default) -->
    <section id="start-screen" style="display:none;">
        <div class="top-bar" style="padding: 12px 16px;">
            <div></div>
            <button id="theme-toggle" class="btn btn-ghost" title="Toggle dark mode">üåô</button>
        </div>
        <div class="center-hero">
            <div>
                <div class="hero-title">Welcome to Blanca</div>
                <div class="hero-tagline subtle">Please use the microphone to begin your prompt. Below are some of the possible topics you can ask and an example question.</div>
                <div class="start-examples">
                    <div class="start-topics-section">
                        <div class="start-section-title subtle">Suggested topics</div>
                        <div id="start-topics-grid" class="start-topics-grid"></div>
                    </div>
                    <div class="start-example-section">
                        <div class="start-section-title subtle">Example question</div>
                        <div id="start-sample-prompt" class="sample-prompt-text"></div>
                    </div>
                </div>
            </div>
        </div>
        <div class="start-input-bar">
            <div class="start-input">
                <input id="start-query-input" placeholder="Ask a question..." />
                <button id="start-mic-btn" class="icon-btn" title="Voice input">üé§</button>
                <button id="start-send-btn" class="send-btn">Send</button>
            </div>
        </div>
    </section>

    <!-- Main App (two panels) -->
    <div class="main-container" id="main-app">
        <div class="left-panel">
            <div class="top-bar">
                <div class="lhs-intro">
                    <div class="title">Welcome to Blanca</div>
                    <div class="subtle">Below are the tools available and an example question to get started.</div>
                </div>
                <button id="theme-toggle" class="btn btn-ghost" title="Toggle dark mode">üåô</button>
            </div>

            <div id="tools-panel" style="margin-top: 8px;">
                <div class="section-title">Available Tools</div>
                <div id="tools-list" class="tools-list">
                    <p class="subtle" style="padding: 8px;">Loading tools...</p>
                </div>
            </div>

            <div id="prompt-ideas-panel" style="margin-top: 12px;">
                <div class="section-title">Prompt Ideas</div>
                <div id="prompt-ideas-content" style="padding: 12px; background: var(--color-surface-light); border-radius: 8px;">
                    <ul id="prompt-ideas-list" class="prompt-ideas-list" style="list-style: disc; margin-left: 18px; font-size: 13px; color: var(--color-text-secondary);">
                        <li class="subtle">Loading ideas...</li>
                    </ul>
                    <button id="toggle-example-btn" class="btn btn-ghost" style="margin-top: 8px; font-size: 12px; padding: 6px 12px;">Need more guidance?</button>
                    <div id="example-question-wrapper" class="hidden" style="margin-top: 8px;">
                        <div class="section-subtitle" style="font-size: 12px; text-transform: uppercase; color: var(--color-text-secondary); letter-spacing: 0.06em;">Sample Prompt</div>
                        <div id="example-question-content" class="sample-prompt-text" style="padding: 10px; background: rgba(0,0,0,0.05); border-radius: 6px; font-size: 13px; font-style: italic; color: var(--color-text-secondary);">
                            <p class="subtle">Loading...</p>
                        </div>
                    </div>
                </div>
            </div>

            <div id="followup-panel" class="hidden" style="margin-top: 8px;">
                <div class="section-title">Suggested Follow-ups</div>
                <ul id="followup-list" class="followup-list"></ul>
            </div>

            <div id="related-topics-panel" class="hidden" style="margin-top: 12px;">
                <div class="section-title">Related Topics</div>
                <div id="related-topics-list" class="related-topics-list"></div>
            </div>
        </div>

    <div id="resizer"></div>

    <div class="right-panel">
        <div class="form-container query-form-container">
            <h3>Query Interface</h3>
            <div id="query-conversation" class="query-conversation">
                </div>
            
            <div class="voice-input-container" style="display: flex; justify-content: center; align-items: center; padding: 40px;">
                <button type="button" id="mic-btn" class="mic-btn-large" title="Press to speak">
                    <div class="voice-level-indicator"></div>
                </button>
            </div>
        </div>

        <button id="save-chat-btn" class="btn" style="margin-top:10px;">Save Chat</button>
    </div>
</div>

    <!-- Floating Tools button -->
    <!-- <button id="tools-fab" class="icon-btn" title="Tools & Raw JSON">üß∞</button> -->

    <!-- Modal for Tools & Raw JSON -->
    <div id="tools-modal" class="modal-backdrop" aria-hidden="true">
        <div class="modal">
            <div class="modal-header">
                <div class="modal-title">Tools & Raw JSON</div>
                <button id="tools-modal-close" class="icon-btn" aria-label="Close">‚úñ</button>
            </div>
            <div class="section-title">Capabilities</div>
            <div class="tool-grid" style="margin-bottom:10px;">
                <div class="tool-card"><h4>Travel</h4><p>Flights, hotels, itineraries</p></div>
                <div class="tool-card"><h4>Science</h4><p>Facts, summaries, lookups</p></div>
                <div class="tool-card"><h4>Math</h4><p>Arithmetic, primes, series</p></div>
                <div class="tool-card"><h4>Trivia</h4><p>General knowledge Q&A</p></div>
            </div>
            <div class="section-title inline-controls">
                <span>Raw JSON</span>
                <button id="toggle-raw-btn" class="btn btn-ghost" style="padding: 4px 8px; font-size: 12px;">Show</button>
            </div>
            <pre id="json-content" class="hidden"></pre>
        </div>
    </div>
<script>
    // Theme handling
    (function initTheme(){
        const saved = localStorage.getItem('theme') || 'light';
        if (saved === 'dark') document.documentElement.setAttribute('data-theme','dark');
        const buttons = document.querySelectorAll('#theme-toggle');
        const setIcon = (btn) => { if (!btn) return; btn.textContent = document.documentElement.getAttribute('data-theme') === 'dark' ? '‚òÄÔ∏è' : 'üåô'; };
        buttons.forEach(setIcon);
        document.addEventListener('click', (e)=>{
            if (e.target && e.target.id === 'theme-toggle'){
                const cur = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'light';
                const next = cur === 'dark' ? 'light' : 'dark';
                document.documentElement.setAttribute('data-theme', next === 'dark' ? 'dark' : '');
                localStorage.setItem('theme', next);
                document.querySelectorAll('#theme-toggle').forEach(setIcon);
            }
        });
    })();

    // Track conversation log for saving later
    const conversationLog = [];
    let sessionStart = new Date().toISOString();
    let isRecording = false;
    let startSamplePrompt = '';
    let latestUserPrompt = '';
    let lastUserQueryText = '';
    const relatedTopicsState = { topics: [], followUps: [], source: 'none' };
    let keywordTopicIndex = [];
    let keywordTopicItems = [];
    let relatedFetchToken = 0;

    // Modal handling and raw JSON toggler (modal)
    const toolsFab = document.getElementById('tools-fab');
    const toolsModal = document.getElementById('tools-modal');
    const toolsModalClose = document.getElementById('tools-modal-close');
    const rawPre = document.getElementById('json-content');
    const rawBtn = document.getElementById('toggle-raw-btn');
    if (toolsFab && toolsModal && toolsModalClose) {
        toolsFab.addEventListener('click', ()=>{ toolsModal.classList.add('show'); });
        toolsModalClose.addEventListener('click', ()=>{ toolsModal.classList.remove('show'); });
        toolsModal.addEventListener('click', (e)=>{ if (e.target === toolsModal) toolsModal.classList.remove('show'); });
    }
    if (rawBtn && rawPre) {
        rawBtn.addEventListener('click', ()=>{
            const hidden = rawPre.classList.toggle('hidden');
            rawBtn.textContent = hidden ? 'Show' : 'Hide';
        });
    }

    // Transition from start screen to main app
    const startScreen = document.getElementById('start-screen');
    const mainApp = document.getElementById('main-app');
    function transitionToMain(){
        if (mainApp.classList.contains('hidden')){
            startScreen.classList.add('fade-out');
            setTimeout(()=>{ startScreen.style.display = 'none'; mainApp.classList.remove('hidden'); }, 200);
        }
    }
    // --- Start screen topics and sample prompt ---
    const ALL_TOPICS = [
        { title: 'Travel', desc: 'Flights, hotels, itineraries' },
        { title: 'Science', desc: 'Facts, summaries, lookups' },
        { title: 'Math', desc: 'Arithmetic, primes, series' },
        { title: 'Trivia', desc: 'General knowledge Q&A' },
        { title: 'Shopping', desc: 'Compare prices, find deals' },
        { title: 'Coding', desc: 'APIs, debugging, snippets' },
        { title: 'Health', desc: 'Wellness info, nutrition' },
        { title: 'Finance', desc: 'Budgets, markets, taxes' },
        { title: 'News', desc: 'Headlines, summaries' },
        { title: 'Education', desc: 'Study help, quizzes' },
        { title: 'Sports', desc: 'Scores, schedules, stats' },
        { title: 'Weather', desc: 'Forecasts and advisories' }
    ];
    const SAMPLE_PROMPTS = [
        'Find flights from SFO to NYC next Tuesday under $300 and a 2-night hotel near Times Square.',
        'Summarize the key differences between mitosis and meiosis with examples.',
        'Write a function to compute the nth Fibonacci number and show the first 10.',
        'What is the capital of Brazil and two facts about it?',
        'Compare the MacBook Air M2 vs. Dell XPS 13 for programming and battery life.'
    ];
    const TOPIC_SYNONYM_MAP = {
        physics: ['physics', 'mechanics', 'mechanic', 'quantum', 'gravity', 'force', 'forces', 'energy', 'motion', 'optics', 'electromagnetism', 'relativity', 'thermodynamics', 'waves'],
        search: ['search', 'lookup', 'google', 'bing', 'find', 'discover', 'locate', 'query', 'information', 'research'],
        trivia: ['trivia', 'facts', 'fact', 'quiz', 'questions', 'curiosity', 'knowledge'],
        math: ['math', 'mathematics', 'algebra', 'geometry', 'calculus', 'statistics', 'arithmetic', 'numbers', 'equations'],
        weather: ['weather', 'forecast', 'temperature', 'rain', 'climate', 'conditions', 'storm', 'humidity'],
        finance: ['finance', 'stocks', 'markets', 'budget', 'investing', 'investment', 'money', 'economy', 'economic'],
        coding: ['coding', 'programming', 'debug', 'debugging', 'code', 'software', 'api', 'development', 'compute'],
        travel: ['travel', 'trip', 'journey', 'flights', 'flight', 'hotel', 'vacation', 'itinerary', 'tourism'],
        health: ['health', 'wellness', 'nutrition', 'fitness', 'exercise', 'diet', 'medical', 'medicine'],
        sports: ['sports', 'game', 'games', 'scores', 'athletics', 'leagues', 'teams', 'tournament'],
        news: ['news', 'headlines', 'breaking', 'articles', 'media', 'press', 'reports', 'reporting'],
        education: ['education', 'study', 'learning', 'school', 'teaching', 'quiz', 'lesson', 'class']
    };
    function pickRandom(arr, n){
        const a = arr.slice();
        for (let i=a.length-1;i>0;i--){ const j=Math.floor(Math.random()*(i+1)); [a[i],a[j]]=[a[j],a[i]]; }
        return a.slice(0, n);
    }
    function renderStartTopics(){
        const grid = document.getElementById('start-topics-grid');
        if (grid){
            grid.innerHTML = '';
            pickRandom(ALL_TOPICS, 4).forEach(t => {
                const card = document.createElement('div');
                card.className = 'start-topic-card';
                const title = document.createElement('div');
                title.className = 'start-topic-title';
                title.textContent = t.title;
                const desc = document.createElement('div');
                desc.className = 'start-topic-desc';
                desc.textContent = t.desc;
                card.appendChild(title);
                card.appendChild(desc);
                grid.appendChild(card);
            });
        }
        startSamplePrompt = pickRandom(SAMPLE_PROMPTS, 1)[0] || '';
        const sampleEl = document.getElementById('start-sample-prompt');
        if (sampleEl) sampleEl.textContent = startSamplePrompt ? `Try asking: ‚Äú${startSamplePrompt}‚Äù` : '';
    }
    // Load and display BFCL tools
    function generatePromptIdeas(tools) {
        const ideas = [];
        if (!tools || tools.length === 0) {
            return [
                'Describe a personal goal or plan and ask the assistant how it might use the available tools to help.',
                'Invent a scenario and challenge the assistant to figure out which tool (if any) should be used.',
                'Ask for suggestions first, then refine your request into a detailed plan.'
            ];
        }

        const toolNames = tools.map(t => t.name.replace(/_/g, ' '));
        const toolDescriptions = tools.map(t => t.description || '').map(desc => desc.charAt(0).toLowerCase() + desc.slice(1));

        ideas.push(`Describe your own situation where the assistant should ${toolDescriptions[0]}. Focus on the details that matter to you.`);

        if (toolNames.length >= 2) {
            ideas.push(`Create a challenge that makes the assistant combine <strong>${toolNames[0]}</strong> and <strong>${toolNames[1]}</strong> in a single response.`);
        }

        ideas.push('Invite the assistant to brainstorm multiple approaches before choosing which tool (if any) to call.');

        return ideas;
    }

    function renderPromptIdeas(ideas) {
        const listEl = document.getElementById('prompt-ideas-list');
        if (!listEl) return;

        listEl.innerHTML = '';
        ideas.forEach(text => {
            const li = document.createElement('li');
            li.innerHTML = text;
            listEl.appendChild(li);
        });
    }

    function loadBFCLTools() {
        fetch('/get_bfcl_tools')
            .then(r => r.json())
            .then(data => {
                const toolsList = document.getElementById('tools-list');
                const exampleQuestionContent = document.getElementById('example-question-content');
                const toggleExampleBtn = document.getElementById('toggle-example-btn');
                
                if (data.tools && data.tools.length > 0) {
                    // Store tools for metadata tracking
                    currentToolsShown = data.tools.map(t => ({
                        name: t.name,
                        description: t.description
                    }));
                    
                    toolsList.innerHTML = '';
                    data.tools.forEach(tool => {
                        const toolCard = document.createElement('div');
                        toolCard.className = 'tool-card';
                        toolCard.style.cssText = 'padding: 12px; margin-bottom: 8px; background: var(--color-surface-light); border-radius: 8px; border-left: 3px solid var(--color-primary);';
                        
                        const toolName = document.createElement('div');
                        toolName.style.cssText = 'font-weight: 600; margin-bottom: 4px; color: var(--color-primary);';
                        toolName.textContent = tool.name;
                        
                        const toolDesc = document.createElement('div');
                        toolDesc.style.cssText = 'font-size: 14px; color: var(--color-text-secondary);';
                        toolDesc.textContent = tool.description;
                        
                        toolCard.appendChild(toolName);
                        toolCard.appendChild(toolDesc);
                        toolsList.appendChild(toolCard);
                    });
                } else {
                    toolsList.innerHTML = '<p class="subtle" style="padding: 8px;">No tools available</p>';
                    currentToolsShown = [];
                }

                fetchedExamplePrompt = data.exampleQuestion || '';
                exampleQuestionContent.innerHTML = '<p class="subtle">Click the button above to view a sample prompt.</p>';
                exampleRevealed = false;
                currentExamplePrompt = '';
                if (toggleExampleBtn) toggleExampleBtn.textContent = 'Need more guidance?';

                currentPromptIdeas = generatePromptIdeas(currentToolsShown);
                renderPromptIdeas(currentPromptIdeas);
            })
            .catch(err => {
                console.warn('Failed to load BFCL tools', err);
                document.getElementById('tools-list').innerHTML = '<p class="subtle" style="padding: 8px;">Error loading tools</p>';
                document.getElementById('example-question-content').innerHTML = '<p class="subtle">Error loading example</p>';
                renderPromptIdeas([
                    'Think of a real task you need help with and describe it in your own words.',
                    'Ask the assistant to suggest possible tool workflows before committing to one.',
                    'Focus on outcomes you care about and invite the assistant to figure out the steps.'
                ]);
            });
    }

    // Handle example prompt reveal
    document.getElementById('toggle-example-btn')?.addEventListener('click', () => {
        const wrapper = document.getElementById('example-question-wrapper');
        const exampleContent = document.getElementById('example-question-content');
        const toggleBtn = document.getElementById('toggle-example-btn');
        if (!wrapper || !exampleContent || !toggleBtn) return;

        const isHidden = wrapper.classList.contains('hidden');
        if (isHidden) {
            wrapper.classList.remove('hidden');
            toggleBtn.textContent = 'Hide sample prompt';
            exampleContent.innerHTML = fetchedExamplePrompt
                ? `<p>"${fetchedExamplePrompt}"</p>`
                : '<p class="subtle">No example available</p>';
            currentExamplePrompt = fetchedExamplePrompt || '';
            exampleRevealed = true;
        } else {
            wrapper.classList.add('hidden');
            toggleBtn.textContent = 'Need more guidance?';
            exampleContent.innerHTML = '<p class="subtle">Click the button above to view a sample prompt.</p>';
            currentExamplePrompt = '';
            exampleRevealed = false;
        }
    });
    
    // Render at load
    renderStartTopics();
    loadBFCLTools(); // Load BFCL tools on page load
    fetch('{{ url_for('static', filename='data/example_functions.json') }}')
        .then(r=>r.json())
        .then(data => { if (data && Array.isArray(data.topics)) buildKeywordTopicIndex(data.topics); })
        .catch(err => console.warn('Failed to load topic catalog', err));
    // Start screen controls (send, mic)
    const startQueryInput = document.getElementById('start-query-input');
    const startSendBtn = document.getElementById('start-send-btn');
    const startMicBtn = document.getElementById('start-mic-btn');

    startSendBtn?.addEventListener('click', ()=>{
        const q = (startQueryInput.value || '').trim(); if (!q) return;
        transitionToMain();
        document.getElementById('query-input').value = q;
        updateLatestPromptPanel(q);
        refreshRelatedSuggestions(q);
        document.querySelector('#query-form button[type="submit"]').click();
        // Clear the start screen input to prevent caching
        startQueryInput.value = '';
        // Reset submission flag
        startIsSubmitting = false;
    });
    
    // Add Enter key support for start screen
    startQueryInput?.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') {
            e.preventDefault();
            const q = (startQueryInput.value || '').trim(); if (!q) return;
            transitionToMain();
            document.getElementById('query-input').value = q;
            updateLatestPromptPanel(q);
            refreshRelatedSuggestions(q);
            document.querySelector('#query-form button[type="submit"]').click();
            // Clear the start screen input to prevent caching
            startQueryInput.value = '';
            // Reset submission flag
            startIsSubmitting = false;
        }
    });

    // Start screen Deepgram streaming functions
    let startSocket, startMicrophone, startProcessor;
    let startHasFinalTranscript = false;
    let startIsSubmitting = false; // Flag to prevent re-recording during submission
    let startVoiceMetadata = {
        words: [],
        utterances: [],
        session_start: new Date().toISOString(),
        total_duration: 0.0
    };
    
    async function startScreenDeepgramStreaming() {
        if (startIsSubmitting) return; // Prevent starting during submission
        isRecording = true;
        startHasFinalTranscript = false;
        startIsSubmitting = false;
        // Reset voice metadata
        startVoiceMetadata = {
            words: [],
            utterances: [],
            session_start: new Date().toISOString(),
            total_duration: 0.0
        };
        startMicBtn.classList.add('recording');
        startQueryInput.placeholder = "üé§ Listening... Speak now!";

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            startMicrophone = stream;

            const wsUrl = (window.location.protocol === 'https:' ? 'wss://' : 'ws://') + window.location.host + '/stt/deepgram';
            startSocket = new WebSocket(wsUrl);

            startSocket.onopen = async () => {
                console.log('Start screen WebSocket connected for Deepgram streaming.');
                try {
                    let mimeType = 'audio/webm;codecs=opus';
                    if (!MediaRecorder.isTypeSupported(mimeType)) mimeType = 'audio/webm';
                    if (!MediaRecorder.isTypeSupported(mimeType)) mimeType = 'audio/ogg;codecs=opus';
                    
                    const mediaRecorder = new MediaRecorder(startMicrophone, { 
                        mimeType: mimeType,
                        audioBitsPerSecond: 16000 
                    });
                    
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && startSocket.readyState === WebSocket.OPEN) {
                            startSocket.send(event.data);
                        }
                    };
                    
                    mediaRecorder.start(250);
                    startProcessor = mediaRecorder;
                    
                } catch (error) {
                    console.error('Error setting up MediaRecorder:', error);
                    startSocket.close();
                }
            };

            startSocket.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);
                    
                    // Capture utterance end events
                    if (data.type === 'UtteranceEnd') {
                        startVoiceMetadata.utterances.push({
                            type: 'utterance_end',
                            timestamp: new Date().toISOString()
                        });
                        console.log('[Start screen] Utterance ended');
                    }
                    
                    if (data.transcript) {
                        startQueryInput.value = data.transcript;
                        console.log('[Start screen] Transcript:', data.transcript, 'Final:', !data.interim);
                        
                        // Extract word-level metadata from backend message
                        if (!data.interim && data.words && Array.isArray(data.words)) {
                            console.log('[Start screen] Got word timestamps:', data.words);
                            for (const word of data.words) {
                                startVoiceMetadata.words.push({
                                    word: word.word || '',
                                    start: word.start || 0.0,
                                    end: word.end || 0.0,
                                    confidence: word.confidence || 0.0,
                                    punctuated_word: word.punctuated_word || word.word || ''
                                });
                                if (word.end > startVoiceMetadata.total_duration) {
                                    startVoiceMetadata.total_duration = word.end;
                                }
                            }
                        }
                        
                        if (data.interim) {
                            startQueryInput.style.fontStyle = 'italic';
                            startQueryInput.style.opacity = '0.8';
                        } else {
                            startQueryInput.style.fontStyle = 'normal';
                            startQueryInput.style.opacity = '1';
                            startHasFinalTranscript = true;
                        }
                    } else if (data.llm_response) {
                        // Ignore LLM interjections on start screen
                        console.log('[Start screen] Ignoring LLM interjection:', data.llm_response);
                    } else if (data.error) {
                        console.error('WebSocket error:', data.error);
                        alert('Streaming error: ' + data.error);
                    } else if (data.status) {
                        console.log('WebSocket status:', data.message);
                    }
                } catch (e) {
                    console.error('Error parsing WebSocket message:', e);
                }
            };

            startSocket.onclose = (event) => {
                console.log('Start screen WebSocket closed:', event.code, event.reason);
            };
            
            startSocket.onerror = (err) => {
                console.error('Start screen WebSocket error:', err);
                if (isRecording) {
                    stopStartScreenDeepgramStreaming();
                }
            };

        } catch (err) {
            console.error('Start screen mic/WebSocket error:', err);
            alert('Unable to access microphone or connect to streaming service: ' + err.message);
            await stopStartScreenDeepgramStreaming();
        }
    }

    async function stopStartScreenDeepgramStreaming() {
        if (!isRecording) return; // Already stopped
        
        console.log('[Start screen] Stopping, has final transcript:', startHasFinalTranscript, 'Input value:', startQueryInput.value);
        console.log('[Start screen] Voice metadata collected:', startVoiceMetadata);
        
        // Stop audio immediately
        if (startProcessor && startProcessor.stop) startProcessor.stop();
        if (startMicrophone) startMicrophone.getTracks().forEach(track => track.stop());
        isRecording = false;
        startIsSubmitting = true; // Lock to prevent re-recording
        startMicBtn.classList.remove('recording');
        startQueryInput.placeholder = "Finalizing...";
        startQueryInput.style.fontStyle = 'normal';
        startQueryInput.style.opacity = '1';
        
        // Brief wait for final transcript, then submit
        setTimeout(() => {
            if (startSocket) startSocket.close();
            startSocket = startMicrophone = startProcessor = null;
            
            const text = startQueryInput.value.trim();
            console.log('[Start screen] Ready to submit, text:', text);
            
            // Save voice metadata to backend
            if (text && startVoiceMetadata.words.length > 0) {
                console.log('[Start screen] Saving voice metadata...');
                fetch('/save_voice_metadata', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        transcript: text,
                        metadata: startVoiceMetadata
                    })
                }).then(r => r.json())
                  .then(d => console.log('[Start screen] Voice metadata saved:', d))
                  .catch(err => console.error('[Start screen] Failed to save metadata:', err));
            }
            
            if (text) {
                startQueryInput.placeholder = "Submitting...";
                startSendBtn.click();
            } else {
                startQueryInput.placeholder = "Ask a question...";
                startIsSubmitting = false; // Reset if no submission
            }
        }, 500); // Reduced delay
    }
    
    // Start screen chunked recording functions
    async function startScreenChunkedRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mimeType = chooseAudioMime();
            mediaRecorder = mimeType ? new MediaRecorder(stream, { mimeType }) : new MediaRecorder(stream);
            const res = await fetch('/stt/start', { method: 'POST' });
            const data0 = await res.json(); 
            if (!res.ok || !data0.stt_sid) throw new Error(data0.error || 'Failed to start STT session');
            sttSid = data0.stt_sid; 
            isRecording = true; 
            startMicBtn.classList.add('recording');
            startQueryInput.placeholder = "Recording... Click mic to stop.";
            
            mediaRecorder.addEventListener('dataavailable', async (e) => {
                if (e.data && e.data.size > 0 && isRecording) {
                    const fd = new FormData();
                    const ext = extForMime(mediaRecorder.mimeType);
                    const file = new File([e.data], `chunk_${Date.now()}.${ext}`, { type: mediaRecorder.mimeType });
                    fd.append('audio', file);
                    try { await fetch('/stt/chunk', { method: 'POST', body: fd }); } catch {}
                }
            });
            mediaRecorder.start(2000);
        } catch (err) { 
            alert('Unable to access microphone: ' + err.message); 
        }
    }
    
    async function stopStartScreenChunkedRecording() {
        if (!mediaRecorder || mediaRecorder.state === 'inactive') return;
        isRecording = false; 
        mediaRecorder.stop(); 
        mediaRecorder.stream.getTracks().forEach(t=>t.stop());
        startMicBtn.classList.remove('recording');
        startQueryInput.placeholder = "Finalizing transcription...";
        
        try { 
            const res2 = await fetch('/stt/stop', { method: 'POST' }); 
            const data = await res2.json(); 
            if (data.text) { 
                startQueryInput.value = data.text;
                // Auto-submit after transcription completes
                startSendBtn.click();
            } else if (data.error) {
                console.error('STT error:', data.error);
                alert('Transcription failed: ' + data.error);
            }
        } catch (err) {
            console.error('Failed to stop STT session:', err);
            alert('An error occurred while finalizing transcription.');
        } finally {
            startQueryInput.placeholder = "Ask a question...";
            mediaRecorder = null;
            sttSid = null;
        }
    }
    
    // Start screen mic button - checks backend and routes appropriately
    startMicBtn?.addEventListener('click', async ()=>{
        if (sttBackend === 'deepgram_streaming') {
            if (isRecording) await stopStartScreenDeepgramStreaming(); 
            else await startScreenDeepgramStreaming();
        } else {
            if (isRecording) await stopStartScreenChunkedRecording(); 
            else await startScreenChunkedRecording();
        }
    });
    // --- Voice Input: Conditional logic for STT backend ---
    const sttBackend = '{{ stt_backend }}';
    const micBtn = document.getElementById('mic-btn');
    let hasUserPrompted = false; // Track if user has made their first prompt

    // --- Session tracking for organized recordings ---
    const sessionId = 'session_' + new Date().toISOString().replace(/[-:]/g, '').replace(/\..+/, '').replace('T', '_');
    let promptNumber = 0; // Track prompt number in this session
    console.log(`Session started: ${sessionId}`);

    // --- Logic for Deepgram Streaming STT ---
    let socket;
    let microphone;
    let processor;

    let currentTranscript = ''; // Track current transcript
    let liveUserMessage = null; // Track the live user message element
    let audioRecorder = null; // MediaRecorder for saving audio
    let audioChunks = []; // Store audio chunks
    let currentRecordingPath = null; // Track current recording path
    let intentionalClose = false; // Track if connection close is intentional
    let recordingStartTime = null; // Track when recording started
    let recordingEndTime = null; // Track when recording ended
    
    // Track context metadata (tools shown, example prompt)
    let currentToolsShown = [];
    let fetchedExamplePrompt = '';
    let currentExamplePrompt = '';
    let exampleRevealed = false;
    let currentPromptIdeas = [];
    
    async function startDeepgramStreaming() {
        console.log('Starting Deepgram streaming...');
        promptNumber++; // Increment prompt number for this session
        isRecording = true;
        micBtn.classList.add('recording');
        currentTranscript = '';
        audioChunks = []; // Reset audio chunks
        currentRecordingPath = null;
        intentionalClose = false; // Reset flag for new connection
        recordingStartTime = new Date().toISOString(); // Capture start time
        recordingEndTime = null;
        console.log(`Recording prompt ${promptNumber} in ${sessionId}`);
        
        // Create a live user message in the conversation
        const conversation = document.getElementById('query-conversation');
        liveUserMessage = document.createElement('div');
        liveUserMessage.className = 'message-user';
        liveUserMessage.style.opacity = '0.7'; // Dimmed while recording
        liveUserMessage.style.fontStyle = 'italic';
        liveUserMessage.textContent = 'Listening...';
        conversation.appendChild(liveUserMessage);
        conversation.scrollTop = conversation.scrollHeight;

        try {
            console.log('Requesting microphone access...');
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            microphone = stream;
            console.log('Microphone access granted');
            
            // Setup MediaRecorder to capture audio for saving
            const mimeType = 'audio/webm;codecs=opus';
            audioRecorder = new MediaRecorder(stream, { mimeType });
            audioRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    audioChunks.push(e.data);
                }
            };
            audioRecorder.start(100); // Collect chunks every 100ms
            console.log('Audio recording started');

            // Setup Web Audio API for voice level detection
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const micSource = audioContext.createMediaStreamSource(stream);
            
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.5;  // Less smoothing for faster response
            micSource.connect(analyser);
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
            
            // Animation loop to update voice level indicator
            let animationFrameId;
            function updateVoiceLevel() {
                if (!isRecording) {
                    cancelAnimationFrame(animationFrameId);
                    return;
                }
                
                analyser.getByteFrequencyData(dataArray);
                
                // Calculate average volume with emphasis on voice frequencies
                let sum = 0;
                const voiceRangeStart = Math.floor(dataArray.length * 0.1);
                const voiceRangeEnd = Math.floor(dataArray.length * 0.6);
                for (let i = voiceRangeStart; i < voiceRangeEnd; i++) {
                    sum += dataArray[i];
                }
                const average = sum / (voiceRangeEnd - voiceRangeStart);
                
                // Amplify and map volume with non-linear scaling for better sensitivity
                const normalized = Math.min(average / 128, 1.0);  // Normalize to 0-1 (more sensitive)
                const amplified = Math.pow(normalized, 0.7);  // Exponential curve
                const scale = 0.3 + (amplified * 1.4);  // Range from 0.3 to 1.7
                
                voiceLevelIndicator.style.transform = `translate(-50%, -50%) scale(${scale})`;
                
                animationFrameId = requestAnimationFrame(updateVoiceLevel);
            }
            
            updateVoiceLevel();

            const wsUrl = (window.location.protocol === 'https:' ? 'wss://' : 'ws://') + window.location.host + '/stt/deepgram';
            console.log('Connecting to WebSocket:', wsUrl);
            socket = new WebSocket(wsUrl);

            socket.onopen = async () => {
                console.log('‚úì WebSocket connected for Deepgram streaming.');
                try {
                    // Use MediaRecorder with a more compatible format
                    let mimeType = 'audio/webm;codecs=opus';
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/webm';
                    }
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/ogg;codecs=opus';
                    }
                    
                    const mediaRecorder = new MediaRecorder(microphone, { 
                        mimeType: mimeType,
                        audioBitsPerSecond: 16000 
                    });
                    
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && socket.readyState === WebSocket.OPEN) {
                            console.log('Sending audio chunk, size:', event.data.size);
                            socket.send(event.data);
                        }
                    };
                    
                    mediaRecorder.onerror = (event) => {
                        console.error('MediaRecorder error:', event.error);
                    };
                    
                    mediaRecorder.start(250); // Send chunks every 250ms for better stability and less load
                    processor = mediaRecorder; // Store reference for cleanup
                    
                } catch (error) {
                    console.error('Error setting up MediaRecorder:', error);
                    socket.close();
                }
            };

            socket.onmessage = (event) => {
                console.log('Received WebSocket message:', event.data);
                try {
                    const data = JSON.parse(event.data);
                    
                    if (data.transcript) {
                        // Real-time transcript updates
                        currentTranscript = data.transcript;
                        console.log('Real-time transcript:', data.transcript, data.interim ? '(interim)' : '(final)');
                        
                        // Update live user message in conversation
                        if (liveUserMessage && data.transcript.trim()) {
                            liveUserMessage.textContent = data.transcript;
                            liveUserMessage.style.opacity = data.interim ? '0.7' : '0.85';
                            liveUserMessage.style.fontStyle = data.interim ? 'italic' : 'normal';
                            
                            // Auto-scroll to keep message visible
                            const conversation = document.getElementById('query-conversation');
                            conversation.scrollTop = conversation.scrollHeight;
                        }
                        
                    } else if (data.llm_response) {
                        // LLM responded (either manually triggered or automatic)
                        const responseType = data.type === 'manual_submit' ? 'Manual submit' : 'Auto interjection';
                        console.log(`${responseType} - LLM response:`, data.llm_response);
                        console.log('User transcript:', data.user_transcript);
                        
                        const conversation = document.getElementById('query-conversation');
                        
                        // Remove the live user message if it exists
                        if (liveUserMessage && liveUserMessage.parentNode) {
                            liveUserMessage.remove();
                            liveUserMessage = null;
                        }
                        
                        // Add the final user message (plain text, no pause markers)
                        if (data.user_transcript && data.user_transcript.trim()) {
                            const userMessage = document.createElement('div');
                            userMessage.className = 'message-user';
                            userMessage.textContent = data.user_transcript.trim();
                            userMessage.style.opacity = '1'; // Full opacity
                            userMessage.style.fontStyle = 'normal'; // Not italic
                            conversation.appendChild(userMessage);
                            
                            // Hide example question after first prompt
                            if (!hasUserPrompted) {
                                hasUserPrompted = true;
                                const examplePanel = document.getElementById('example-question-panel');
                                if (examplePanel) examplePanel.style.display = 'none';
                            }
                        }
                        
                        // Then add LLM response
                        const botMessage = document.createElement('div');
                        botMessage.className = 'message-bot';
                        botMessage.textContent = data.llm_response;
                        conversation.appendChild(botMessage);
                        conversation.scrollTop = conversation.scrollHeight;
                        
                        // Clear the transcript
                        currentTranscript = '';
                        
                        // Save audio recording if we have one and a recording_path
                        if (data.recording_path && audioChunks.length > 0) {
                            console.log(`Saving audio recording for ${data.recording_path}...`);
                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                            const formData = new FormData();
                            formData.append('audio', audioBlob, 'audio.webm');
                            formData.append('recording_path', data.recording_path);
                            
                            fetch('/save_audio_recording', {
                                method: 'POST',
                                body: formData
                            })
                            .then(r => r.json())
                            .then(result => {
                                console.log('‚úì Audio recording saved:', result);
                                audioChunks = []; // Clear chunks after saving
                            })
                            .catch(err => console.error('Failed to save audio recording:', err));
                        }
                        
                        // If this was a manual submit, close the WebSocket connection
                        if (data.type === 'manual_submit') {
                            console.log('Received LLM response for manual submit, closing connection');
                            intentionalClose = true; // Mark as intentional before closing
                            if (socket) {
                                socket.close();
                                socket = null;
                            }
                        }
                        
                    } else if (data.error) {
                        console.error('WebSocket error:', data.error);
                        alert('Streaming error: ' + data.error);
                    } else if (data.status) {
                        console.log('WebSocket status:', data.message);
                    }
                } catch (e) {
                    console.error('Error parsing WebSocket message:', e);
                }
            };

            socket.onclose = (event) => {
                console.log('WebSocket closed:', event.code, event.reason);
                if (!intentionalClose) {
                    console.warn('‚ö†Ô∏è Unexpected WebSocket close');
                }
                isRecording = false;
                micBtn.classList.remove('recording');
                if (processor && processor.stop) processor.stop();
                if (microphone) microphone.getTracks().forEach(track => track.stop());
            };
            socket.onerror = (err) => {
                console.error('‚ùå WebSocket error:', err);
                if (!intentionalClose) {
                    alert('Connection error. Please try again.');
                }
            };

        } catch (err) {
            console.error('‚ùå Mic/WebSocket error:', err);
            if (err.name === 'NotAllowedError') {
                alert('Microphone access denied. Please allow microphone access in your browser settings.');
            } else {
                alert('Unable to access microphone: ' + err.message);
            }
            isRecording = false;
            micBtn.classList.remove('recording');
            
            // Stop audio recorder on error
            if (audioRecorder && audioRecorder.state === 'recording') {
                audioRecorder.stop();
            }
            audioRecorder = null;
            audioChunks = [];
            
            // Remove live user message on error
            if (liveUserMessage && liveUserMessage.parentNode) {
                liveUserMessage.remove();
                liveUserMessage = null;
            }
        }
    }

    async function stopDeepgramStreaming() {
        console.log('User manually stopping recording...');
        intentionalClose = true; // Mark this as an intentional close
        recordingEndTime = new Date().toISOString(); // Capture end time
        
        // Stop audio recorder
        if (audioRecorder && audioRecorder.state === 'recording') {
            audioRecorder.stop();
            console.log('Audio recording stopped');
        }
        
        // Stop microphone and recording but keep WebSocket open for LLM response
        if (processor && processor.stop) processor.stop();
        if (microphone) microphone.getTracks().forEach(track => track.stop());
        isRecording = false;
        micBtn.classList.remove('recording');
        
        // Reset voice level indicator
        const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
        if (voiceLevelIndicator) {
            voiceLevelIndicator.style.transform = 'translate(-50%, -50%) scale(0.3)';
        }
        
        // Make the live user message solid (not italic) while waiting for LLM response
        if (liveUserMessage) {
            liveUserMessage.style.opacity = '1';
            liveUserMessage.style.fontStyle = 'normal';
        }
        
        microphone = processor = audioRecorder = null;
        
        // Send finalize message to trigger LLM response with complete transcript
        // Keep socket open to receive the response
        if (socket && socket.readyState === WebSocket.OPEN) {
            socket.send(JSON.stringify({ 
                action: 'finalize',
                session_id: sessionId,
                prompt_number: promptNumber,
                recording_start_time: recordingStartTime,
                recording_end_time: recordingEndTime,
                tools_shown: currentToolsShown,
                example_prompt_shown: currentExamplePrompt,
                prompt_ideas: currentPromptIdeas,
                is_first_prompt_in_session: (promptNumber === 1)
            }));
            console.log(`Sent finalize message for ${sessionId}/prompt_${promptNumber} - keeping connection open for LLM response`);
        }
        
        // Note: Socket will be closed after receiving LLM response (handled in onmessage)
    }

    // --- Logic for chunked recording (Whisper/Gemini) ---
    let mediaRecorder = null;
    let sttSid = null;

    function chooseAudioMime() {
        const options = ['audio/webm;codecs=opus', 'audio/webm', 'audio/ogg;codecs=opus', 'audio/ogg'];
        for (const t of options) {
            if (window.MediaRecorder && MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t)) return t;
        }
        return '';
    }

    function extForMime(m) {
        if (!m) return 'webm';
        if (m.includes('ogg')) return 'ogg';
        return 'webm';
    }

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mimeType = chooseAudioMime();
            mediaRecorder = mimeType ? new MediaRecorder(stream, { mimeType }) : new MediaRecorder(stream);
            
            // Setup Web Audio API for voice level detection
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const micSource = audioContext.createMediaStreamSource(stream);
            
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.5;  // Less smoothing for faster response
            micSource.connect(analyser);
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
            
            // Animation loop to update voice level indicator
            let animationFrameId;
            function updateVoiceLevel() {
                if (!isRecording) {
                    cancelAnimationFrame(animationFrameId);
                    return;
                }
                
                analyser.getByteFrequencyData(dataArray);
                
                // Calculate average volume with emphasis on voice frequencies
                let sum = 0;
                const voiceRangeStart = Math.floor(dataArray.length * 0.1);
                const voiceRangeEnd = Math.floor(dataArray.length * 0.6);
                for (let i = voiceRangeStart; i < voiceRangeEnd; i++) {
                    sum += dataArray[i];
                }
                const average = sum / (voiceRangeEnd - voiceRangeStart);
                
                // Amplify and map volume with non-linear scaling for better sensitivity
                const normalized = Math.min(average / 128, 1.0);  // Normalize to 0-1 (more sensitive)
                const amplified = Math.pow(normalized, 0.7);  // Exponential curve
                const scale = 0.3 + (amplified * 1.4);  // Range from 0.3 to 1.7
                
                voiceLevelIndicator.style.transform = `translate(-50%, -50%) scale(${scale})`;
                
                animationFrameId = requestAnimationFrame(updateVoiceLevel);
            }
            
            updateVoiceLevel();
            
            const res = await fetch('/stt/start', { method: 'POST' });
            const data0 = await res.json();
            if (!res.ok || !data0.stt_sid) throw new Error(data0.error || 'Failed to start STT session');
            sttSid = data0.stt_sid;

            mediaRecorder.addEventListener('dataavailable', async (e) => {
                if (e.data && e.data.size > 0 && isRecording) {
                    const fd = new FormData();
                    const ext = extForMime(mediaRecorder.mimeType);
                    const file = new File([e.data], `chunk_${Date.now()}.${ext}`, { type: mediaRecorder.mimeType });
                    fd.append('audio', file);
                    try { await fetch('/stt/chunk', { method: 'POST', body: fd }); } catch (err) { console.error('Chunk upload failed', err); }
                }
            });

            mediaRecorder.start(2000);
            isRecording = true;
            micBtn.classList.add('recording');
        } catch (err) {
            console.error('Mic error:', err);
            alert('Unable to access microphone: ' + err.message);
        }
    }

    async function stopRecording() {
        if (!mediaRecorder || mediaRecorder.state === 'inactive') return;
        isRecording = false;
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(t => t.stop());
        micBtn.classList.remove('recording');
        
        // Reset voice level indicator
        const voiceLevelIndicator = document.querySelector('.voice-level-indicator');
        if (voiceLevelIndicator) {
            voiceLevelIndicator.style.transform = 'translate(-50%, -50%) scale(0.3)';
        }

        try {
            const res = await fetch('/stt/stop', { method: 'POST' });
            const data = await res.json();
            if (data.text) {
                // Display user message
                const conversation = document.getElementById('query-conversation');
                const userMessage = document.createElement('div');
                userMessage.className = 'message-user';
                userMessage.textContent = data.text;
                conversation.appendChild(userMessage);
                conversation.scrollTop = conversation.scrollHeight;
                
                // Hide example question after first prompt
                if (!hasUserPrompted) {
                    hasUserPrompted = true;
                    const examplePanel = document.getElementById('example-question-panel');
                    if (examplePanel) examplePanel.style.display = 'none';
                }
                
                // Send query to backend
                const queryData = new FormData();
                queryData.append('query', data.text);
                
                fetch('/query', {
                    method: 'POST',
                    body: queryData
                })
                .then(response => response.json())
                .then(responseData => {
                    const botMessage = document.createElement('div');
                    botMessage.className = 'message-bot';
                    botMessage.textContent = responseData.response || (responseData.error ? ('Error: ' + responseData.error) : '');
                    conversation.appendChild(botMessage);
                    conversation.scrollTop = conversation.scrollHeight;
                })
                .catch(error => {
                    console.error('Query error:', error);
                });
            } else if (data.error) {
                console.error('STT error:', data.error);
                alert('Transcription failed: ' + data.error);
            }
        } catch (e) {
            console.error('Failed to stop STT session:', e);
            alert('An error occurred while finalizing transcription.');
        } finally {
            mediaRecorder = null;
            sttSid = null;
        }
    }

    // Main mic button event listener
    micBtn?.addEventListener('click', async () => {
        if (sttBackend === 'deepgram_streaming') {
            if (isRecording) await stopDeepgramStreaming(); else await startDeepgramStreaming();
        } else {
            if (isRecording) await stopRecording(); else await startRecording();
        }
    });

    // Save chat button handler
        document.getElementById('save-chat-btn').addEventListener('click', function() {
            const payload = {
                sessionInfo: {
                    sessionId: crypto.randomUUID(),
                    userId: 'anonymous',
                    startTimestamp: sessionStart,
                    endTimestamp: new Date().toISOString(),
                    llmModel: 'gemini-1.5-flash-latest'
                },
                context: {
                    initialContent: latestUserPrompt || '',
                    finalContent: conversationLog.length ? conversationLog[conversationLog.length - 1].content : ''
                },
                conversationLog: conversationLog,
                evaluation: {
                    surveyResponses: {},
                    userComments: ''
                }
            };
            fetch('/save_chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            })
            .then(r => r.json())
            .then(d => {
                if (d.error) {
                    alert('Failed to save: ' + d.error);
                } else {
                    alert('Saved: ' + d.dirName);
                }
            })
            .catch(err => {
                alert('Save error: ' + err);
            });
        });

        // --- Similarity helpers (trigram + cosine) ---
        function trigramVector(text){
            const v = new Map();
            const t = (text || '').toLowerCase();
            for (let i=0;i<t.length-2;i++){
                const tri = t.slice(i,i+3);
                v.set(tri, (v.get(tri)||0)+1);
            }
            return v;
        }
        function wordVector(text){
            const v = new Map();
            const tokens = (text||'').toLowerCase().split(/[^a-z0-9]+/).filter(Boolean);
            for (const tok of tokens){ v.set(tok, (v.get(tok)||0)+1); }
            return v;
        }
        function cosineSim(v1, v2){
            if (!v1 || !v2) return 0;
            let dot=0, norm1=0, norm2=0;
            for (const [,w] of v1) norm1 += w*w;
            for (const [,w] of v2) norm2 += w*w;
            const smaller = v1.size < v2.size ? v1 : v2;
            const other = smaller===v1 ? v2 : v1;
            for (const [k,w] of smaller){ const w2 = other.get(k)||0; if (w2) dot += w*w2; }
            if (!norm1 || !norm2) return 0;
            return dot / (Math.sqrt(norm1)*Math.sqrt(norm2));
        }
        function buildKeywordTopicIndex(topics){
            if (!Array.isArray(topics)) return;
            keywordTopicItems = topics.slice();
            keywordTopicIndex = keywordTopicItems.map(t => {
                const text = [t.title, t.description, ...(t.functions||[]).map(f=>`${f.name} ${f.description}`)].join(' ').toLowerCase();
                const synonyms = new Set((TOPIC_SYNONYM_MAP[t.id] || []).map(s => s.toLowerCase()));
                const tokens = new Set(text.split(/[^a-z0-9]+/).filter(Boolean));
                synonyms.forEach(s => tokens.add(s));
                return {
                    topic: t,
                    triVector: trigramVector(text),
                    wordVector: wordVector(text),
                    tokens,
                    synonyms
                };
            });
        }

        function keywordTopicFallback(prompt){
            const q = (prompt || '').toLowerCase();
            if (!q || !keywordTopicIndex.length) return keywordTopicItems.slice(0, 3).map(t => ({ title: t.title, description: t.description || '' }));
            const qTri = trigramVector(q);
            const qWord = wordVector(q);
            const qTokens = new Set(q.split(/[^a-z0-9]+/).filter(Boolean));
            const scored = keywordTopicIndex.map(entry => {
                const tri = cosineSim(qTri, entry.triVector);
                const word = cosineSim(qWord, entry.wordVector);
                let boost = 0;
                qTokens.forEach(tok => {
                    if (entry.tokens.has(tok)) boost += 0.04;
                    if (entry.synonyms.has(tok)) boost += 0.08;
                });
                return { entry, score: (0.6 * tri) + (0.4 * word) + boost };
            }).sort((a,b)=>b.score - a.score);
            const filtered = scored.filter(s => s.score > 0.01).slice(0, 3);
            const picks = filtered.length ? filtered : scored.slice(0, 3);
            const mapped = picks.map(item => ({
                title: item.entry.topic.title,
                description: item.entry.topic.description || ''
            })).filter(t => t.title);
            if (!mapped.length){
                return ALL_TOPICS.slice(0, 3).map(t => ({ title: t.title, description: t.desc || '' }));
            }
            return mapped;
        }

        function updateLatestPromptPanel(text){
            if (typeof text === 'string') {
                latestUserPrompt = text.trim();
            }
            const panel = document.getElementById('latest-prompt-panel');
            const content = document.getElementById('latest-prompt-content');
            if (!panel || !content) return;
            if (latestUserPrompt){
                content.textContent = latestUserPrompt;
                panel.classList.remove('hidden');
            } else {
                content.textContent = '';
                panel.classList.add('hidden');
            }
        }

        function renderFollowupExamples(followUps){
            const panel = document.getElementById('followup-panel');
            const list = document.getElementById('followup-list');
            if (!panel || !list) return;
            list.innerHTML = '';
            const items = Array.isArray(followUps) ? followUps.filter(Boolean).map(f => String(f).trim()).filter(Boolean).slice(0, 2) : [];
            if (!items.length){
                panel.classList.add('hidden');
                return;
            }
            for (const q of items){
                const li = document.createElement('li');
                li.textContent = q;
                list.appendChild(li);
            }
            panel.classList.remove('hidden');
        }

        function renderRelatedTopics(topics){
            const panel = document.getElementById('related-topics-panel');
            const list = document.getElementById('related-topics-list');
            if (!panel || !list) return;
            list.innerHTML = '';
            const items = Array.isArray(topics) ? topics.filter(Boolean).slice(0, 3) : [];
            if (!items.length){
                panel.classList.add('hidden');
                return;
            }
            items.forEach(t => {
                const item = document.createElement('div');
                item.className = 'related-topic-item';
                const title = document.createElement('div');
                title.className = 'related-topic-title';
                title.textContent = t.title || '';
                const desc = document.createElement('div');
                desc.className = 'related-topic-desc';
                desc.textContent = t.description || '';
                item.appendChild(title);
                if (desc.textContent) item.appendChild(desc);
                list.appendChild(item);
            });
            panel.classList.remove('hidden');
        }

        async function refreshRelatedSuggestions(prompt){
            const trimmed = (prompt || '').trim();
            const requestToken = ++relatedFetchToken;
            if (!trimmed){
                relatedTopicsState.topics = [];
                relatedTopicsState.followUps = [];
                relatedTopicsState.source = 'none';
                renderRelatedTopics([]);
                renderFollowupExamples([]);
                return;
            }
            try {
                const res = await fetch('/related_topics', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt: trimmed })
                });
                if (!res.ok) throw new Error(`HTTP ${res.status}`);
                const data = await res.json();
                if (requestToken !== relatedFetchToken) return;
                relatedTopicsState.topics = Array.isArray(data.topics) ? data.topics : [];
                relatedTopicsState.followUps = Array.isArray(data.followUps) ? data.followUps : [];
                relatedTopicsState.source = data.source || 'unknown';
                if (!relatedTopicsState.topics.length){
                    relatedTopicsState.topics = keywordTopicFallback(trimmed);
                }
                renderRelatedTopics(relatedTopicsState.topics);
                renderFollowupExamples(relatedTopicsState.followUps);
            } catch (err) {
                console.error('Failed to fetch related topics', err);
                if (requestToken !== relatedFetchToken) return;
                relatedTopicsState.topics = keywordTopicFallback(trimmed);
                relatedTopicsState.followUps = [];
                relatedTopicsState.source = 'fallback-client';
                renderRelatedTopics(relatedTopicsState.topics);
                renderFollowupExamples([]);
            }
        }

        // Draggable resizer
        const resizer = document.getElementById('resizer');
        const leftPanel = document.querySelector('.left-panel');
        const rightPanel = document.querySelector('.right-panel');

        const resize = (e) => {
            const isHorizontal = window.innerWidth > 768;
            if (isHorizontal) {
                const newWidth = e.clientX;
                if (newWidth > 200 && newWidth < window.innerWidth - 200) {
                    leftPanel.style.flexBasis = `${newWidth}px`;
                }
            } else {
                const newHeight = e.clientY;
                if (newHeight > 100 && newHeight < window.innerHeight - 100) {
                    leftPanel.style.flexBasis = `${newHeight}px`;
                    leftPanel.style.height = `${newHeight}px`;
                }
            }
        };

        resizer.addEventListener('mousedown', (e) => {
            e.preventDefault();
            document.addEventListener('mousemove', resize);
            document.addEventListener('mouseup', () => {
                document.removeEventListener('mousemove', resize);
            });
        });
</script>
</body>
</html>