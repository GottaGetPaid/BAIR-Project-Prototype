## BAIR Project Prototype — Web App Guide

This repository contains a simple Flask web app for experimenting with LLM prompts using BFCL-style JSON inputs. It lets you:

- Upload a JSON describing a prompt and its callable tools (toolboxes and tools).
- Preview the JSON on the left (including a grouped Tools & Toolboxes view and a raw JSON toggle).
- Auto-submit the JSON’s question to a chat on the right.
- Save the chat as structured JSON under `test-sessions/`.
- Optional: record a short voice query (local Whisper or Gemini STT if configured).

The “model” response defaults to a placeholder (“please insert an api key for a model”) unless a valid API key and SDK is configured.

## Configuration

The app is configured via a `.env` file in the project root. Create this file by copying `.env.example` and filling in the values.

```env
# .env

# Model backend: noop | huggingface | gemini
MODEL_BACKEND=huggingface

# --- Hugging Face --- 
# Model ID from the Hub (e.g., meta-llama/Meta-Llama-3-8B-Instruct)
HF_MODEL_ID=meta-llama/Meta-Llama-3-8B-Instruct
# Your Hugging Face API Token
HUGGING_FACE_API_TOKEN="your-hf-key"

# --- Google --- 
# Your Google API Key for Gemini
GOOGLE_API_KEY="your-google-key"

# --- STT Backend --- 
# Options: whisper_local | gemini | whisper
STT_BACKEND=whisper_local

# --- Flask --- 
FLASK_SECRET_KEY=dev-secret
```

The `.env` file is included in `.gitignore` and should not be committed to version control.

---

## Quick Start (Bash / Zsh)

1) Create and activate a virtual environment (Python 3.10+):

```bash
python3 -m venv venv
source venv/bin/activate
```

2) Install dependencies:

```bash
pip install -r requirements.txt
```

3) Run the app (either command works):

```bash
python web/app.py
# or
export FLASK_APP="web/app.py"; flask run --debug
```

Open http://127.0.0.1:5000 in your browser.

---

## Quick Start (Windows PowerShell)

1) Create and activate a virtual environment (Python 3.10+):

```powershell
python -m venv .\venv
.\venv\Scripts\Activate.ps1
```

2) Install dependencies:

```powershell
pip install -r requirements.txt
```

3) Run the app (either command works):

```powershell
python .\web\app.py
# or
$env:FLASK_APP = "web/app.py"; flask run --debug
```

Open http://127.0.0.1:5000 in your browser.

---

## Cleaning Up

A `clean.sh` script is included to remove temporary files and directories generated by the app, such as test sessions, uploaded files, and `__pycache__` directories.

To run it, execute the following command from the project root:

```bash
./clean.sh
```

---

## Using the Site

Left panel: Prompt toolbox Preview
- Theme button toggles light/dark (persists via localStorage).
- Tools & Toolboxes: functions are grouped by toolbox (prefix before the dot). Each toolbox is collapsible, and each tool shows its description and parameter schema.
- Raw JSON: hidden by default; click “Show/Hide” to toggle.

Right panel: Chat & Upload
- Query Interface: type a message or use the mic button for voice input (optional; see Voice Input below).
- Upload a JSON file: choose a BFCL-style JSON file and click Upload. The app will:
  - Display the JSON details on the left (ID, Question, Tools & Toolboxes, Raw JSON toggle).
  - Auto-fill and submit the question into the chat on the right.
- Save Chat: persists the current conversation to disk (see Where chats are saved).

Sample JSON
- Ready-to-use examples are provided in the `queries/` directory, including `BFCL_single.json` and `BFCL_multiple.jsonl`.
- Expected shape (simplified):
  - `id`: string
  - `question`: nested list(s) of turns with `{ role: 'user', content: '...' }`
  - `function` (or `functions`): array of tool specs with `name`, `description`, and `parameters` schema
- Example tool naming: `math_toolkit.sum_of_multiples` where `math_toolkit` is the toolbox and `sum_of_multiples` is the tool.

Model response
- If the selected `MODEL_BACKEND` is not configured correctly (e.g., missing API key), the app will return a default message.

---

## Where chats are saved (and how)

When you click “Save Chat”, the app writes a session folder and JSON file here:

```
test-sessions/
  <N>-<YYYYMMDD-HHMMSS>-<model>-<user>/
    session-data.json
```

- N is an incrementing number.
- model and user are slugified from session info (defaults to `gemini-1.5-flash-latest` and `anonymous`).

File contents follow this structure:

```json
{
  "sessionInfo": {
    "sessionId": "...",
    "userId": "anonymous",
    "startTimestamp": "...",
    "endTimestamp": "...",
    "llmModel": "gemini-1.5-flash-latest"
  },
  "context": {
    "initialContent": "...",  
    "finalContent": "..."     
  },
  "conversationLog": [
    { "turn": 1, "role": "user", "inputType": "text",  "content": "...", "timestamp": "..." },
    { "turn": 2, "role": "assistant", "inputType": "model", "content": "...", "timestamp": "..." }
  ],
  "evaluation": {
    "surveyResponses": {},
    "userComments": ""
  }
}
```

---

## JSON format tips

- The app supports either a single object or an array of objects (it will pick the first).
- `question` is parsed for user content (nested arrays of `{ role, content }`). That content is auto-submitted to the chat.
- Tools are grouped by the prefix in `name` before the first `.` to form a toolbox.

---

## Optional: Voice input

- Mic button records short audio, sends it to the backend, and the transcription is auto-submitted as the query.
- Local Whisper (default path in code): requires FFmpeg and the `openai-whisper` Python package.
    - **Install FFmpeg**: FFmpeg must be installed on your system and available in your PATH.
    - **macOS (using Homebrew):** `brew install ffmpeg`
    - **Debian/Ubuntu:** `sudo apt update && sudo apt install ffmpeg`
    - **Windows (using Chocolatey):** `choco install ffmpeg`
  - Install Whisper: `pip install openai-whisper`
  - Set `STT_BACKEND=whisper_local` in `.env`.
- Gemini STT (alternative): set `STT_BACKEND=gemini` in `.env` and export `GOOGLE_API_KEY`, plus install the module: `pip install google-generativeai`.

If you don’t need voice, you can ignore the mic button.

---

## Optional: Configure a real model

By default, the `MODEL_BACKEND` is set to `noop`. To use a real model, set the `MODEL_BACKEND` in your `.env` file to one of the following:

- **`gemini`**: Uses the Gemini 1.5 Flash model. Requires `GOOGLE_API_KEY` to be set.
- **`huggingface`**: Uses the Hugging Face Inference API. Requires `HUGGING_FACE_API_TOKEN` and a `HF_MODEL_ID` to be set.

---

## Minimal self-play (for later)

The repository includes a minimal turn-based “self-play” engine (not wired to the web UI yet):

- `engine/` orchestrates turn-taking.
- `games/template_game.py` shows how to implement a game.

---

## Repository layout

- `web/` — Flask app
  - `app.py` — backend routes for JSON upload/parse, chat, voice STT, and saving chats
  - `templates/upload.html` — two-panel UI with toolbox visualization and dark mode
  - `static/styles.css` — CSS for the web app
- `queries/` — sample JSONs (`BFCL_single.json`, `BFCL_multiple.jsonl`)
- `test-sessions/` — generated chat sessions (ignored by git)
- `engine/`, `games/` — basic self-play scaffolding 
- `models/` — model provider scaffolding (optional for now)
- `config.py` — environment configuration

If you only want to test the web features, you don’t need any large model downloads.